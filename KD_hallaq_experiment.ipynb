{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import torch_pruning as tp\n",
    "from mobilenetv3 import mobilenetv3\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_lightning as L\n",
    "import h5py\n",
    "from torch.utils.data import Dataset\n",
    "import copy\n",
    "import torch.nn as nn \n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "import csv\n",
    "from torch.profiler import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad.hallaq/workarea/venv/lib/python3.10/site-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Free up cached memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Clear all the gradients\n",
    "torch.cuda.reset_max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFClassifier(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = 3e-4\n",
    "        self.lr_ignored = 3e-4  # Learning rate for ignored layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Initialize lists for different parameter groups\n",
    "        ignored_layers_params = []\n",
    "        other_layers_params = []\n",
    "\n",
    "        # Collect parameters of specific layers based on layer names and conditions\n",
    "        ignored_params_set = set()\n",
    "        for name, m in self.model.named_modules():\n",
    "            if any(name.startswith(f'blocks.{i}') for i in range(3)) or (isinstance(m, torch.nn.Linear) and m.out_features == 2):\n",
    "                ignored_layers_params += list(m.parameters())\n",
    "                ignored_params_set.update(m.parameters())  # Add to set to avoid duplicates\n",
    "\n",
    "        # Other parameters: Exclude the ignored layers' parameters\n",
    "        other_layers_params = [p for p in self.model.parameters() if p not in ignored_params_set]\n",
    "\n",
    "        # Create the optimizer with different learning rates for different parameter groups\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': ignored_layers_params, 'lr': self.lr_ignored},  # Lower learning rate for ignored layers\n",
    "            {'params': other_layers_params, 'lr': self.lr}  # Default learning rate for other layers\n",
    "        ], weight_decay=0)\n",
    "\n",
    "        # Learning rate scheduler\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1)\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': {'scheduler': lr_scheduler, 'interval': 'step'}}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('test_loss', loss, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCheckpoint(L.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_model = None\n",
    "\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        # Access validation loss from the trainer's metrics\n",
    "        val_loss = trainer.callback_metrics.get('val_loss')\n",
    "        if val_loss is not None and val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.best_model = pl_module.model\n",
    "            # Save the best model\n",
    "            torch.save(self.best_model, 'best_model.pth')\n",
    "            print(f\"New best model saved with validation loss {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R22_H5_Dataset(Dataset):\n",
    "    def __init__(self, data_file, label='label', iqlabel='iq_data'):\n",
    "        self.data_file = data_file\n",
    "        self.label = label\n",
    "        self.iqlabel = iqlabel\n",
    "\n",
    "    def __len__(self):\n",
    "        with h5py.File(self.data_file, 'r') as f:\n",
    "            length = len(f[self.label])\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.data_file, 'r') as f:\n",
    "            iq_data = f[self.iqlabel][idx]\n",
    "            label = f[self.label][idx]\n",
    "        return iq_data, label\n",
    "    \n",
    "    def get_metadata(self, idx):\n",
    "        with h5py.File(self.data_file, 'r') as f:\n",
    "            metadata = {\n",
    "                'recording': f['recording'][idx].decode('utf-8)'),\n",
    "                'category': f['category'][idx].decode('utf-8)')\n",
    "            }\n",
    "        return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(trained_model, prune_method, prune_amount, train_loader):\n",
    "\n",
    "    # torch.manual_seed(80) \n",
    "    model =  copy.deepcopy(trained_model)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "\n",
    "    example_length = 4096\n",
    "\n",
    "    if prune_method == 'channel_pruning_Taylor_importance':\n",
    "        imp = tp.importance.TaylorImportance() \n",
    "\n",
    "        ignored_layers_group1 = []\n",
    "\n",
    "        for name, m in model.named_modules():\n",
    "            # Check if the module is within Sequential(3), Sequential(4), Sequential(5) or the classifier\n",
    "            if any(name.startswith(f'blocks.{i}') for i in range(3)) or (isinstance(m, torch.nn.Linear) and m.out_features == 2):\n",
    "                ignored_layers_group1.append(m)\n",
    "\n",
    "        ignored_layers_group2 = []\n",
    "    \n",
    "        for name, m in model.named_modules():\n",
    "            # Check if the module is within Sequential(0), Sequential(1), Sequential(2) or the classifier\n",
    "            if any(name.startswith(f'blocks.{i+3}') for i in range(3)) or (isinstance(m, torch.nn.Linear) and m.out_features == 2):\n",
    "                ignored_layers_group2.append(m) \n",
    "\n",
    "\n",
    "        batch = next(iter(train_loader))\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "       \n",
    "        iterative_steps= 1\n",
    "        pruner_group1 = tp.pruner.MagnitudePruner( \n",
    "            model,\n",
    "            example_inputs=x,\n",
    "            importance=imp,\n",
    "            pruning_ratio=prune_amount, \n",
    "            # pruning_ratio_dict = {model.conv1: 0.2, model.layer2: 0.8}, # customized pruning ratios for layers or blocks\n",
    "            ignored_layers=ignored_layers_group1,\n",
    "            iterative_steps= iterative_steps,\n",
    "            global_pruning=True,\n",
    "            # isomorphic=True\n",
    "        )\n",
    "\n",
    "        pruner_group2 = tp.pruner.MagnitudePruner( \n",
    "            model,\n",
    "            example_inputs=x,\n",
    "            importance=imp,\n",
    "            pruning_ratio=0.7, \n",
    "            # pruning_ratio_dict = {model.conv1: 0.2, model.layer2: 0.8}, # customized pruning ratios for layers or blocks\n",
    "            ignored_layers=ignored_layers_group2,\n",
    "            iterative_steps= iterative_steps,\n",
    "            global_pruning=True,\n",
    "            # isomorphic=True\n",
    "        )\n",
    "\n",
    "        # prune the model, iteratively if necessary.\n",
    "        for i in range(iterative_steps):\n",
    "\n",
    "            # Taylor expansion requires gradients for importance estimation\n",
    "            if isinstance(imp, tp.importance.TaylorImportance):\n",
    "                \n",
    "                x, y = batch\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                y_hat = model(x)\n",
    "                loss = F.mse_loss(y_hat, y)\n",
    "                loss.backward()\n",
    "\n",
    "            pruner_group1.step()\n",
    "            pruner_group2.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model_checkpoint = 'august22_beam_t.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = '/home/mohammad.hallaq/workarea/MobileNet_compression/data_h5py_files/r22_train.h5'\n",
    "val_data = '/home/mohammad.hallaq/workarea/MobileNet_compression/data_h5py_files/r22_val.h5'\n",
    "test_data = '/home/mohammad.hallaq/workarea/MobileNet_compression/data_h5py_files/r22_test.h5'\n",
    "checkpoint_dir = '/home/mohammad.hallaq/workarea/MobileNet_compression/checkpoints-Copy2'\n",
    "checkpoint_filename = os.path.join(checkpoint_dir, 'august22_beam_t.ckpt')\n",
    "checkpoint =torch.load(checkpoint_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_length = 4096\n",
    "batch_size = 128\n",
    "epochs =30\n",
    "\n",
    "hparams = {\n",
    "    'drop_path_rate': 0.2,\n",
    "    'drop_rate': 0.7,\n",
    "    'learning_rate': 3e-3,\n",
    "    'wd': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_pruning(trained_model, pruning_method, model_name_suffix, train_loader, val_loader, prune_amount):\n",
    "    checkpoint_filename = f\"model_pruned_{model_name_suffix}_amount_{prune_amount}.ckpt\"\n",
    "    final_model_path = f'model_final_pruned_{model_name_suffix}_amount_{prune_amount}.pth'\n",
    "\n",
    "   \n",
    "    if os.path.exists(checkpoint_filename) or os.path.exists(final_model_path):\n",
    "        print(f\"Model {model_name_suffix} at {prune_amount * 100}% pruning already exists. Skipping training.\")\n",
    "        return\n",
    "\n",
    "    pruned_model = prune_model(trained_model, pruning_method, prune_amount, train_loader)\n",
    "\n",
    "    rf_classifier = RFClassifier(pruned_model)\n",
    "\n",
    "    checkpoint_callback = L.callbacks.ModelCheckpoint(\n",
    "        dirpath='.',\n",
    "        filename=checkpoint_filename.replace(\".ckpt\", \"\"),\n",
    "        save_top_k=1,\n",
    "        verbose=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # Create the custom callback\n",
    "    custom_checkpoint = CustomCheckpoint()\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=1,\n",
    "        callbacks=[checkpoint_callback, custom_checkpoint],\n",
    "        accelerator='gpu',\n",
    "        devices=1,\n",
    "        benchmark=True,\n",
    "        precision='32-true',\n",
    "    )\n",
    "\n",
    "    print(f\"Training the model with {pruning_method} applied at {prune_amount * 100}%...\")\n",
    "    trainer.fit(rf_classifier, train_loader, val_loader)\n",
    "\n",
    "    torch.save(rf_classifier.model, final_model_path)\n",
    "\n",
    "    print(f\"Model {pruning_method} at {prune_amount * 100}% pruning saved. \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = '/home/mohammad.hallaq/workarea/AoA-Pruning/data_h5py_files/r22_train.h5'\n",
    "# val_data = '/home/mohammad.hallaq/workarea/AoA-Pruning/data_h5py_files/r22_test.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_length = 4096\n",
    "# batch_size = 128\n",
    "# epochs =30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 268515 examples\n",
      "Validation Set: 29835 examples\n",
      "Testing Set: 74685 examples\n"
     ]
    }
   ],
   "source": [
    "train_set = R22_H5_Dataset(train_data)\n",
    "val_set = R22_H5_Dataset(val_data)\n",
    "test_set = R22_H5_Dataset(test_data)\n",
    "print(f'Training Set: {len(train_set)} examples')\n",
    "print(f'Validation Set: {len(val_set)} examples')\n",
    "print(f'Testing Set: {len(test_set)} examples')\n",
    "\n",
    "num_classes = train_set[0][1].shape[0]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    )\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_set,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    "    )\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = mobilenetv3(\n",
    "    model_size='mobilenetv3_small_050',\n",
    "    num_classes=num_classes,\n",
    "    drop_rate=hparams['drop_rate'],\n",
    "    drop_path_rate=hparams['drop_path_rate'],\n",
    "    in_chans=8\n",
    ")\n",
    "\n",
    "# rf_classifier = RFClassifier.load_from_checkpoint(original_model_checkpoint, model=model)\n",
    "\n",
    "# rf_classifier.to('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix_from_state_dict(state_dict, prefix='model.'):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith(prefix):\n",
    "            new_state_dict[k[len(prefix):]] = v\n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['state_dict'] = remove_prefix_from_state_dict(checkpoint['state_dict'], prefix='model.')\n",
    "\n",
    "original_model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_methods = ['channel_pruning_Taylor_importance']\n",
    "pruning_amounts = [0.95]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = prune_model(original_model, pruning_methods[0], pruning_amounts[0], train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = torch.load('/home/mohammad.hallaq/workarea/MobileNet_compression/best_model(20011_parameters).pth')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "pruned_model = pruned_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 0.00422164 G, #Params: 20.011 K\n"
     ]
    }
   ],
   "source": [
    "example_inputs = torch.randn(1, 8, 4096)\n",
    "example_inputs = example_inputs.to('cuda')  \n",
    "macs, nparams = tp.utils.count_ops_and_params(pruned_model, example_inputs)\n",
    "print(f\"MACs: {macs/1e9} G, #Params: {nparams/1e3} K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import pytorch_lightning as L\n",
    "\n",
    "# class KD_RFClassifier(L.LightningModule):\n",
    "#     def __init__(self, model, teacher_model, alpha=0.8):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             model: The student model that will be trained.\n",
    "#             teacher_model: The pre-trained teacher model.\n",
    "#             alpha: Weight for the distillation loss vs. task loss.\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.model = model                 # Student model\n",
    "#         self.teacher_model = teacher_model  # Teacher model (pre-trained)\n",
    "#         self.teacher_model.eval()           # Ensure teacher model is in evaluation mode\n",
    "#         for param in self.teacher_model.parameters():\n",
    "#             param.requires_grad = False     # Freeze the teacher model parameters\n",
    "        \n",
    "#         self.alpha = alpha                  # Weight between task loss and distillation loss\n",
    "\n",
    "#         # Save hyperparameters if needed\n",
    "#         self.lr = hparams['learning_rate']\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.AdamW(self.parameters(), \n",
    "#                                       lr=hparams['learning_rate'],\n",
    "#                                       weight_decay=hparams['wd'])\n",
    "#         lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "#             optimizer, \n",
    "#             T_max=len(train_loader) * epochs,\n",
    "#         )\n",
    "#         return {\n",
    "#             'optimizer': optimizer,\n",
    "#             'lr_scheduler': {\n",
    "#                 'scheduler': lr_scheduler,\n",
    "#                 'interval': 'step'\n",
    "#             }\n",
    "#         }\n",
    "       \n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "        \n",
    "#         # Forward pass through the student model\n",
    "#         y_hat = self(x)\n",
    "\n",
    "#         # Forward pass through the teacher model (detach to avoid gradient computation)\n",
    "#         with torch.no_grad():\n",
    "#             teacher_outputs = self.teacher_model(x)\n",
    "\n",
    "#         # Calculate task loss (between student model output and ground truth)\n",
    "#         task_loss = F.mse_loss(y_hat, y)\n",
    "\n",
    "#         # Calculate distillation loss (between teacher and student model outputs)\n",
    "#         distillation_loss = F.mse_loss(y_hat, teacher_outputs)\n",
    "        \n",
    "#         # Total loss: weighted combination of task loss and distillation loss\n",
    "#         loss = self.alpha * task_loss + (1 - self.alpha) * distillation_loss\n",
    "\n",
    "#         # Log the losses\n",
    "#         self.log('train_task_loss', task_loss, on_epoch=True, prog_bar=True)\n",
    "#         self.log('train_distillation_loss', distillation_loss, on_epoch=True, prog_bar=True)\n",
    "#         self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "#         return loss\n",
    "\n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "#         y_hat = self(x)\n",
    "#         loss = F.mse_loss(y_hat, y)\n",
    "#         self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "#     def test_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "#         y_hat = self(x)\n",
    "#         loss = F.mse_loss(y_hat, y)\n",
    "#         self.log('test_loss', loss, prog_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as L\n",
    "\n",
    "# Helper class to extract intermediate features from the model\n",
    "class IntermediateLayerGetter(nn.Module):\n",
    "    def __init__(self, model, return_layers):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: The base model to extract features from.\n",
    "            return_layers: A dictionary mapping layer names to their desired output names.\n",
    "                           E.g., {'global_pool': 'teacher_features'}\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.return_layers = return_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = {}\n",
    "        for name, module in self.model._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.return_layers:\n",
    "                out[self.return_layers[name]] = x\n",
    "        return out\n",
    "\n",
    "class KD_RFClassifier(L.LightningModule):\n",
    "    def __init__(self, model, teacher_model, alpha=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: The student model that will be trained.\n",
    "            teacher_model: The pre-trained teacher model.\n",
    "            alpha: Weight for the distillation loss vs. task loss.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model  # Student model\n",
    "        self.teacher_model = teacher_model  # Teacher model (pre-trained)\n",
    "        self.teacher_model.eval()  # Set teacher model to evaluation mode\n",
    "        for param in self.teacher_model.parameters():\n",
    "            param.requires_grad = False  # Freeze the teacher model parameters\n",
    "\n",
    "        self.alpha = alpha  # Weight between task loss and distillation loss\n",
    "\n",
    "        # Define feature extractor modules to get feature maps before flattening\n",
    "        # Extract the feature maps before flattening for both student and teacher\n",
    "        self.teacher_features = IntermediateLayerGetter(self.teacher_model, {'global_pool': 'teacher_features'})\n",
    "        self.student_features = IntermediateLayerGetter(self.model, {'global_pool': 'student_features'})\n",
    "        \n",
    "        # Move the feature extractor to the same device as the student model\n",
    "        self.teacher_features.to(self.device)\n",
    "        self.student_features.to(self.device)\n",
    "\n",
    "        # Add a convolutional layer to adjust student feature map size to match teacher's feature map size\n",
    "        # For example, student feature maps have fewer channels, and teacher has 1024 channels\n",
    "        self.feature_adjustment = nn.Conv1d(\n",
    "            in_channels=self.get_student_feature_channels(),  # Get the number of channels from student feature maps\n",
    "            out_channels=self.get_teacher_feature_channels(),  # Get the number of channels from teacher feature maps\n",
    "            kernel_size=1  # Use 1x1 convolution to adjust only channels\n",
    "        ).to(self.device)\n",
    "\n",
    "    def get_teacher_feature_channels(self):\n",
    "        \"\"\"Helper function to get number of channels in teacher feature maps.\"\"\"\n",
    "        dummy_input = torch.randn(1, 8, 4096).to(self.device)  # Adjust input size to match your model's input\n",
    "        with torch.no_grad():\n",
    "            teacher_features = self.teacher_features(dummy_input)\n",
    "        return teacher_features['teacher_features'].shape[1]\n",
    "\n",
    "    def get_student_feature_channels(self):\n",
    "        \"\"\"Helper function to get number of channels in student feature maps.\"\"\"\n",
    "        dummy_input = torch.randn(1, 8, 4096).to(self.device)   # Adjust input size to match your model's input\n",
    "        student_features = self.student_features(dummy_input)\n",
    "        return student_features['student_features'].shape[1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), \n",
    "                                      lr=hparams['learning_rate'],\n",
    "                                      weight_decay=hparams['wd'])\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, \n",
    "            T_max=len(train_loader) * epochs,\n",
    "        )\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': lr_scheduler,\n",
    "                'interval': 'step'\n",
    "            }\n",
    "        }\n",
    "       \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x, y = x.to(self.device), y.to(self.device)\n",
    "        \n",
    "        # Forward pass through the student model and extract features before flattening\n",
    "        student_features = self.student_features(x)['student_features']\n",
    "        student_outputs = self.model(x)\n",
    "\n",
    "        # Forward pass through the teacher model and extract features before flattening (detach to avoid gradient computation)\n",
    "        with torch.no_grad():\n",
    "            teacher_features = self.teacher_features(x)['teacher_features']\n",
    "\n",
    "        # Adjust the student feature map size to match teacher's feature map size\n",
    "        adjusted_student_features = self.feature_adjustment(student_features)\n",
    "\n",
    "        # Calculate task loss (between student model output and ground truth)\n",
    "        task_loss = F.mse_loss(student_outputs, y)\n",
    "\n",
    "        # Calculate distillation loss on the feature maps (between adjusted student and teacher feature maps)\n",
    "        distillation_loss = F.mse_loss(adjusted_student_features, teacher_features)\n",
    "\n",
    "        # Total loss: weighted combination of task loss and feature distillation loss\n",
    "        loss = distillation_loss #self.alpha * task_loss + (task_loss/distillation_loss)*(1 - self.alpha) * distillation_loss\n",
    "\n",
    "        # Log the losses\n",
    "        self.log('train_task_loss', task_loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_distillation_loss', distillation_loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDCustomCheckpoint(L.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_model = None\n",
    "\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        # Access validation loss from the trainer's metrics\n",
    "        val_loss = trainer.callback_metrics.get('val_loss')\n",
    "        if val_loss is not None and val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.best_model = pl_module.model\n",
    "            # Save the best model\n",
    "            torch.save(self.best_model, 'KD_experiments/best_model.pth')\n",
    "            print(f\"New best model saved with validation loss {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_pruning_and_KD(pruned_model, original_model, pruning_method, model_name_suffix, train_loader, val_loader, prune_amount):\n",
    "    \n",
    "    checkpoint_filename = f\"KD_experiments/model_pruned_{model_name_suffix}_amount_{prune_amount}.ckpt\"\n",
    "    final_model_path = f'KD_experiments/model_final_pruned_{model_name_suffix}_amount_{prune_amount}.pth'\n",
    "\n",
    "    if os.path.exists(checkpoint_filename) or os.path.exists(final_model_path):\n",
    "        print(f\"Model {model_name_suffix} at {prune_amount * 100}% pruning already exists. Skipping training.\")\n",
    "        return\n",
    "\n",
    "    # Ensure models are on the correct device (e.g., GPU if available)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    pruned_model = pruned_model.to(device)\n",
    "    original_model = original_model.to(device)\n",
    "\n",
    "    rf_classifier = KD_RFClassifier(pruned_model, original_model)\n",
    "\n",
    "    checkpoint_callback = L.callbacks.ModelCheckpoint(\n",
    "        dirpath='.',\n",
    "        filename=checkpoint_filename.replace(\".ckpt\", \"\"),\n",
    "        save_top_k=1,\n",
    "        verbose=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min'\n",
    "    )\n",
    "    Custom_callback = KDCustomCheckpoint()\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=30,\n",
    "        callbacks=[checkpoint_callback, Custom_callback],\n",
    "        accelerator='gpu',\n",
    "        devices=1,\n",
    "        benchmark=True,\n",
    "        precision='32-true',\n",
    "    )\n",
    "\n",
    "    print(f\"Training the model with {pruning_method} applied at {prune_amount * 100}%...\")\n",
    "    trainer.fit(rf_classifier, train_loader, val_loader)\n",
    "\n",
    "    torch.save(rf_classifier.model, final_model_path)\n",
    "\n",
    "    print(f\"Model {pruning_method} at {prune_amount * 100}% pruning saved. \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad.hallaq/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/mohammad.hallaq/workarea/MobileNet_compression exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name               | Type                    | Params | Mode \n",
      "-----------------------------------------------------------------------\n",
      "0 | model              | MobileNetV3             | 20.0 K | eval \n",
      "1 | teacher_model      | MobileNetV3             | 548 K  | eval \n",
      "2 | teacher_features   | IntermediateLayerGetter | 548 K  | train\n",
      "3 | student_features   | IntermediateLayerGetter | 20.0 K | train\n",
      "4 | feature_adjustment | Conv1d                  | 13.5 K | train\n",
      "-----------------------------------------------------------------------\n",
      "33.5 K    Trainable params\n",
      "548 K     Non-trainable params\n",
      "582 K     Total params\n",
      "2.328     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "516       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with channel_pruning_Taylor_importance applied at 95.0%...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4dbfc7836644df9b72d4748b37af39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 0.8812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c88481b41ae47fbbf898058e39e0f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422230feab6f49d8aa66c37501739c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 2098: 'val_loss' reached 1127.68091 (best 1127.68091), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/KD_experiments/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d27fe9ace4a46999550f6939cfcb6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 4196: 'val_loss' reached 1051.62183 (best 1051.62183), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/KD_experiments/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90bbf50e21214225a79de65a83bac91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 6294: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f31afcf5a9342e1b9a7d3ba9a73c264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 8392: 'val_loss' reached 1049.66394 (best 1049.66394), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/KD_experiments/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8595751b0fa400baddb813a6fafd093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 10490: 'val_loss' was not in top 1\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1025\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:250\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:190\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:268\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:167\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 167\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1306\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1306\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:153\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:238\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:122\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/optim/adamw.py:165\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 165\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:108\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:144\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:129\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 129\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:317\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m--> 317\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 100\u001b[0m, in \u001b[0;36mKD_RFClassifier.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Forward pass through the student model and extract features before flattening\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m student_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstudent_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudent_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    101\u001b[0m student_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[16], line 22\u001b[0m, in \u001b[0;36mIntermediateLayerGetter.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_layers:\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/timm/models/_efficientnet_blocks.py:292\u001b[0m, in \u001b[0;36mInvertedResidual.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    291\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mse(x)\n\u001b[0;32m--> 292\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_pwl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(x)\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model_with_pruning_and_KD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpruned_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruning_methods\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruning_methods\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruning_amounts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 37\u001b[0m, in \u001b[0;36mtrain_model_with_pruning_and_KD\u001b[0;34m(pruned_model, original_model, pruning_method, model_name_suffix, train_loader, val_loader, prune_amount)\u001b[0m\n\u001b[1;32m     27\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     28\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m     29\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[checkpoint_callback, Custom_callback],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m32-true\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpruning_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m applied at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprune_amount\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(rf_classifier\u001b[38;5;241m.\u001b[39mmodel, final_model_path)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpruning_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprune_amount\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% pruning saved. \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "train_model_with_pruning_and_KD(pruned_model, original_model, pruning_methods[0], pruning_methods[0], train_loader, val_loader, pruning_amounts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in pruning_methods:\n",
    "    for amount in pruning_amounts:\n",
    "        train_model_with_pruning(rf_classifier.model, method, method, train_loader, val_loader, amount)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating The Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = torch.load('/home/mohammad.hallaq/workarea/MobileNet_compression/KD_experiments/best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quiver(all_targets, all_outputs, quiver_path: str):\n",
    "    \"\"\"\n",
    "    Creates and stores the quiver plot for given targets and predicted outputs\n",
    "    :args all_targets:\n",
    "    :args all_outputs:\n",
    "    \"\"\"\n",
    "    predictions_per_target = defaultdict(list)\n",
    "    errors_per_target = dict()\n",
    "\n",
    "    for idx, target_angles_tuple in enumerate(all_targets):\n",
    "        target_tuple = tuple(target_angles_tuple)\n",
    "        predictions_per_target[target_tuple].append(all_outputs[idx])\n",
    "    for target_tuple, list_of_predictions in predictions_per_target.items():\n",
    "        # predictions_per_target[target_tuple] = np.mean(list_of_predictions, axis=0)\n",
    "        errors_per_target[target_tuple] = np.subtract(target_tuple, np.mean(list_of_predictions, axis=0))\n",
    "\n",
    "    unique_targets = list(errors_per_target.keys())\n",
    "    unique_azimuth = [target[0] for target in unique_targets]\n",
    "    unique_elevation = [target[1] for target in unique_targets]\n",
    "    unique_erros = list(errors_per_target.values())\n",
    "    errors_azimuth = [target[0] for target in unique_erros]\n",
    "    errors_elevation = [target[1] for target in unique_erros]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(unique_azimuth, unique_elevation, color='red', label='True Angles')\n",
    "    plt.quiver(unique_azimuth, unique_elevation, errors_azimuth, errors_elevation,\n",
    "                angles='xy', scale_units='xy', scale=1, color='blue', label='Predicted Angles')\n",
    "    plt.xlim([-55, 55])\n",
    "    plt.ylim([-55, 55])\n",
    "    plt.xlabel('Azimuth')\n",
    "    plt.ylabel('Elevation')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.savefig(quiver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 584/584 [00:17<00:00, 32.51batch/s, Val Loss=0.399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Loss = 0.001706707859708288\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "experiment_path = '/home/mohammad.hallaq/workarea/AoA-Pruning/experiments'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "pruned_model = pruned_model.to(device)\n",
    "pruned_model.eval()\n",
    "\n",
    "test_loss, num_samples = 0, 0\n",
    "all_targets, all_outputs = np.zeros([1, 2]), np.zeros([1, 2])\n",
    "with torch.no_grad():\n",
    "    with tqdm(test_loader, desc='Testing', unit='batch') as pbar:\n",
    "        for sample_inputs, targets in pbar:\n",
    "            sample_inputs = sample_inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = pruned_model(sample_inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            num_samples += targets.shape[0]\n",
    "            test_loss += loss.item()/num_samples\n",
    "            all_targets = np.concatenate((all_targets, targets.cpu()))\n",
    "            all_outputs = np.concatenate((all_outputs, outputs.cpu()))\n",
    "            pbar.set_postfix({'Val Loss': test_loss})\n",
    "    all_outputs = all_outputs[1:]\n",
    "    all_targets = all_targets[1:]\n",
    "    test_loss = test_loss / len(val_loader)\n",
    "    print(f\"Test Set Loss = {test_loss}\")\n",
    "    quiver_path = os.path.join(experiment_path, \"testing_quiver_plot.png\")\n",
    "    plot_quiver(all_targets, all_outputs, quiver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model_and_save_to_csv(model, val_loader, device=None, iterations=1, csv_file='model_analysis.csv', model_name=None):\n",
    "  \n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    first_batch = next(iter(val_loader))\n",
    "    input_tensor, true_angles = first_batch\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "    example_inputs = input_tensor.to(device)\n",
    "    print('This is the shape of the input: ', example_inputs.shape)\n",
    "    \n",
    "\n",
    "    analysis_results = {\n",
    "        'model_name': model_name if model_name else model.__class__.__name__,\n",
    "        'model_size_mb (MB)': None,\n",
    "        'GFLOPs (GFLOPs)': None,\n",
    "        'Total_Params (count)': None,\n",
    "        'First_Forward_Pass_Time (s)': None,\n",
    "        'Training_Time (s)': None,\n",
    "        'Inference_Time (s)': None,\n",
    "        'CUDA_Time (ms)': None,\n",
    "        'CPU_Time (ms)': None,\n",
    "        'mse': None,\n",
    "        'mae': None\n",
    "    }\n",
    "    \n",
    " \n",
    "    try:\n",
    "        model.to(device)\n",
    "        example_inputs = example_inputs.to(device)\n",
    "    \n",
    " \n",
    "        flops, params = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "        analysis_results['GFLOPs (GFLOPs)'] = flops  \n",
    "        analysis_results['Total_Params (count)'] = params\n",
    "\n",
    "    except Exception:\n",
    "        pass \n",
    "\n",
    "\n",
    "    try:\n",
    "        torch.save(model.state_dict(), \"temp.pth\")\n",
    "        model_size = os.path.getsize(\"temp.pth\") / (1024 * 1024)  # Convert to MB\n",
    "        os.remove(\"temp.pth\")\n",
    "        analysis_results['model_size_mb (MB)'] = model_size\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            start_time = time.time()\n",
    "            _ = model(example_inputs)\n",
    "            end_time = time.time()\n",
    "        analysis_results['First_Forward_Pass_Time (s)'] = end_time - start_time\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        iterations = 1000 # Number of iterations within each test\n",
    "        num_tests = 20 # Number of times to run the inference test\n",
    "        all_times = [] # To store the inference times of each test\n",
    "\n",
    "        for test in range(num_tests):\n",
    "            start_time = time.time()\n",
    "            for _ in range(iterations):\n",
    "                with torch.no_grad():\n",
    "                    _ = model(example_inputs)\n",
    "            end_time = time.time()\n",
    "            inference_time = (end_time - start_time) / iterations\n",
    "            all_times.append(inference_time)\n",
    "        \n",
    "        average_inference_time = sum(all_times) / num_tests\n",
    "        \n",
    "        analysis_results['Inference_Time (s)'] = average_inference_time\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()  \n",
    "                with profile(use_cuda=True) as prof:\n",
    "                    _ = model(example_inputs)\n",
    "                # Collect CUDA times\n",
    "                cuda_time_total = sum(evt.cuda_time for evt in prof.key_averages())\n",
    "                cpu_time_total = sum(evt.cpu_time_total for evt in prof.key_averages())\n",
    "                analysis_results['CUDA_Time (ms)'] = cuda_time_total / 1e3\n",
    "                analysis_results['CPU_Time (ms)'] = cpu_time_total / 1e3\n",
    "            else:\n",
    "                with profile(use_cuda=False) as prof:\n",
    "                    _ = model(example_inputs)\n",
    "                # Collect CPU times only\n",
    "                cpu_time_total = sum(evt.cpu_time_total for evt in prof.key_averages())\n",
    "                analysis_results['CPU_Time (ms)'] = cpu_time_total / 1e3\n",
    "    except Exception as e:\n",
    "        print(f\"Error during profiling: {e}\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        model.eval()\n",
    "        y_preds = []\n",
    "        y_true = []\n",
    "        with torch.inference_mode():\n",
    "            for sample in val_loader:\n",
    "                data, target = sample[0].to(device), sample[1].to(device)\n",
    "                y_true += target.tolist()\n",
    "                output = model(data)\n",
    "                y_preds += output.cpu().tolist()\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_preds = np.array(y_preds)\n",
    "\n",
    "\n",
    "        mse = np.square(y_true - y_preds).mean()\n",
    "        mae = np.absolute(y_true - y_preds).mean()\n",
    "\n",
    "        analysis_results['mse'] = mse\n",
    "        analysis_results['mae'] = mae\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    file_exists = os.path.isfile(csv_file)\n",
    "    \n",
    "    with open(csv_file, mode='a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=analysis_results.keys())\n",
    "        \n",
    "        if not file_exists:\n",
    "            writer.writeheader()  \n",
    "        \n",
    "        writer.writerow(analysis_results)  \n",
    "\n",
    "    return analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the shape of the input:  torch.Size([128, 8, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-09-27 07:00:56 1531592:1531592 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-09-27 07:00:56 1531592:1531592 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-09-27 07:00:56 1531592:1531592 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Free up cached memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Clear all the gradients\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "\n",
    "example_inputs = torch.randn(128, 1, 8, 4096)  \n",
    "\n",
    "results = analyze_model_and_save_to_csv(original_model, val_loader, device=None, iterations=1, csv_file='model_analysis.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'MobileNetV3',\n",
       " 'model_size_mb (MB)': 2.1971359252929688,\n",
       " 'GFLOPs (GFLOPs)': 23439648.0,\n",
       " 'Total_Params (count)': 548482,\n",
       " 'First_Forward_Pass_Time (s)': 0.0075342655181884766,\n",
       " 'Training_Time (s)': None,\n",
       " 'Inference_Time (s)': 0.01575898751020432,\n",
       " 'CUDA_Time (ms)': 3.2840884089211326,\n",
       " 'CPU_Time (ms)': 47.796,\n",
       " 'mse': 1.2235874766855361,\n",
       " 'mae': 0.576736716231774}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'MobileNetV3',\n",
       " 'model_size_mb (MB)': 2.1971359252929688,\n",
       " 'GFLOPs (GFLOPs)': 23439648.0,\n",
       " 'Total_Params (count)': 548482,\n",
       " 'First_Forward_Pass_Time (s)': 0.010128259658813477,\n",
       " 'Training_Time (s)': None,\n",
       " 'Inference_Time (s)': 0.018788700044155122,\n",
       " 'CUDA_Time (ms)': 3.9351331035248798,\n",
       " 'CPU_Time (ms)': 53.335,\n",
       " 'mse': 1.2235874766855361,\n",
       " 'mae': 0.576736716231774}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape\n",
    "input_size = (1, 8, 4096)  # For MNIST-like input\n",
    "\n",
    "# Capture summary into a string and write to file\n",
    "with open(\"model_structure.txt\", \"w\") as f:\n",
    "    summary_string = summary(pruned_model, input_size=input_size, verbose=0)\n",
    "    f.write(str(summary_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_deviation(loader, model):\n",
    "    device = next(model.parameters()).device\n",
    "    model.to(device)\n",
    "    total_azimuth_deviation = 0\n",
    "    total_elevation_deviation = 0\n",
    "    num_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs, true_angles = batch\n",
    "            inputs, true_angles = inputs.to(device), true_angles.to(device)\n",
    "            predicted = model(inputs).cpu().numpy()\n",
    "            true_angles = true_angles.cpu().numpy()\n",
    "            azimuth_deviation = np.abs(predicted[:, 0] - true_angles[:, 0])\n",
    "            elevation_deviation = np.abs(predicted[:, 1] - true_angles[:, 1])\n",
    "        \n",
    "            total_azimuth_deviation += np.sum(azimuth_deviation)\n",
    "            total_elevation_deviation += np.sum(elevation_deviation)\n",
    "            num_samples += len(true_angles)\n",
    "    avg_azimuth_deviation = total_azimuth_deviation / num_samples\n",
    "    avg_elevation_deviation = total_elevation_deviation / num_samples\n",
    "    return avg_azimuth_deviation, avg_elevation_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0799208594635883 2.202856791666683\n"
     ]
    }
   ],
   "source": [
    "avg_azim_dev, avg_elev_dev = calculate_average_deviation(val_loader, pruned_model)\n",
    "print(avg_azim_dev, avg_elev_dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
