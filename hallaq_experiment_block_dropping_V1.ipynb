{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/mohammad.hallaq/workarea/MobileNet_compression\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(globals()[\"_dh\"][0])\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "os.chdir('/home/mohammad.hallaq/workarea/MobileNet_compression') # change accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import torch_pruning as tp\n",
    "from mobilenetv3 import mobilenetv3\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_lightning as L\n",
    "import h5py\n",
    "from torch.utils.data import Dataset\n",
    "import copy\n",
    "import torch.nn as nn \n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "import csv\n",
    "from torch.profiler import profile\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_device = 'cuda:2' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad.hallaq/workarea/venv/lib/python3.10/site-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Free up cached memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Clear all the gradients\n",
    "torch.cuda.reset_max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFClassifier(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = 5e-4\n",
    "        self.lr_ignored = 5e-4  # Learning rate for ignored layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Initialize lists for different parameter groups\n",
    "        ignored_layers_params = []\n",
    "        other_layers_params = []\n",
    "\n",
    "        # Collect parameters of specific layers based on layer names and conditions\n",
    "        ignored_params_set = set()\n",
    "        for name, m in self.model.named_modules():\n",
    "            if any(name.startswith(f'blocks.{i}') for i in range(3)) or (isinstance(m, torch.nn.Linear) and m.out_features == 2):\n",
    "                ignored_layers_params += list(m.parameters())\n",
    "                ignored_params_set.update(m.parameters())  # Add to set to avoid duplicates\n",
    "\n",
    "        # Other parameters: Exclude the ignored layers' parameters\n",
    "        other_layers_params = [p for p in self.model.parameters() if p not in ignored_params_set]\n",
    "\n",
    "        # Create the optimizer with different learning rates for different parameter groups\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': ignored_layers_params, 'lr': self.lr_ignored},  # Lower learning rate for ignored layers\n",
    "            {'params': other_layers_params, 'lr': self.lr}  # Default learning rate for other layers\n",
    "        ], weight_decay=0)\n",
    "\n",
    "        # Learning rate scheduler\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1)\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': {'scheduler': lr_scheduler, 'interval': 'step'}}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('test_loss', loss, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCheckpoint(L.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_model = None\n",
    "\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        # Access validation loss from the trainer's metrics\n",
    "        val_loss = trainer.callback_metrics.get('val_loss')\n",
    "        if val_loss is not None and val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.best_model = pl_module.model\n",
    "            # Save the best model\n",
    "            torch.save(self.best_model, 'pruning_results/best_model.pth')\n",
    "            print(f\"New best model saved with validation loss {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R22_H5_Dataset(Dataset):\n",
    "    def __init__(self, data_file, label='label', iqlabel='iq_data'):\n",
    "        self.data_file = data_file\n",
    "        self.label = label\n",
    "        self.iqlabel = iqlabel\n",
    "\n",
    "    def __len__(self):\n",
    "        with h5py.File(self.data_file, 'r') as f:\n",
    "            length = len(f[self.label])\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.data_file, 'r') as f:\n",
    "            iq_data = f[self.iqlabel][idx]\n",
    "            label = f[self.label][idx]\n",
    "        return iq_data, label\n",
    "    \n",
    "    def get_metadata(self, idx):\n",
    "        with h5py.File(self.data_file, 'r') as f:\n",
    "            metadata = {\n",
    "                'recording': f['recording'][idx].decode('utf-8)'),\n",
    "                'category': f['category'][idx].decode('utf-8)')\n",
    "            }\n",
    "        return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prune_model(trained_model, prune_method, prune_amount, train_loader):\n",
    "\n",
    "#     # torch.manual_seed(80) \n",
    "#     model =  copy.deepcopy(trained_model)\n",
    "#     device = general_device\n",
    "#     model.to(device)\n",
    "\n",
    "#     example_length = 4096\n",
    "\n",
    "#     if prune_method == 'channel_pruning_Taylor_importance':\n",
    "#         imp = tp.importance.TaylorImportance() \n",
    "\n",
    "#         ignored_layers_group1 = []\n",
    "\n",
    "#         for name, m in model.named_modules():\n",
    "#             # Check if the module is within Sequential(3), Sequential(4), Sequential(5) or the classifier\n",
    "#             if any(name.startswith(f'blocks.{i}') for i in range(3)) or (isinstance(m, torch.nn.Linear) and m.out_features == 2):\n",
    "#                 ignored_layers_group1.append(m)\n",
    "\n",
    "#         ignored_layers_group2 = []\n",
    "    \n",
    "#         for name, m in model.named_modules():\n",
    "#             # Check if the module is within Sequential(0), Sequential(1), Sequential(2) or the classifier\n",
    "#             if any(name.startswith(f'blocks.{i+3}') for i in range(3)) or (isinstance(m, torch.nn.Linear) and m.out_features == 2):\n",
    "#                 ignored_layers_group2.append(m) \n",
    "\n",
    "#         batch = next(iter(train_loader))\n",
    "#         x, y = batch\n",
    "#         x = x.to(device)\n",
    "       \n",
    "#         iterative_steps = 1\n",
    "#         pruner_group1 = tp.pruner.MagnitudePruner( \n",
    "#             model,\n",
    "#             example_inputs=x,\n",
    "#             importance=imp,\n",
    "#             pruning_ratio=prune_amount, \n",
    "#             ignored_layers=ignored_layers_group1,\n",
    "#             iterative_steps= iterative_steps,\n",
    "#         )\n",
    "\n",
    "#         pruner_group2 = tp.pruner.MagnitudePruner( \n",
    "#             model,\n",
    "#             example_inputs=x,\n",
    "#             importance=imp,\n",
    "#             pruning_ratio=0.5, \n",
    "#             ignored_layers=ignored_layers_group2,\n",
    "#             iterative_steps= iterative_steps,\n",
    "#         )\n",
    "\n",
    "#         # prune the model, iteratively if necessary.\n",
    "#         for i in range(iterative_steps):\n",
    "#             if isinstance(imp, tp.importance.TaylorImportance):\n",
    "#                 x, y = batch\n",
    "#                 x = x.to(device)\n",
    "#                 y = y.to(device)\n",
    "#                 y_hat = model(x)\n",
    "#                 loss = F.mse_loss(y_hat, y)\n",
    "#                 loss.backward()\n",
    "\n",
    "#             pruner_group1.step()\n",
    "#             pruner_group2.step()\n",
    "\n",
    "#     # Free up GPU memory\n",
    "#     del x, y, batch  # Remove any tensors on the GPU\n",
    "\n",
    "#     torch.cuda.empty_cache()  # Clear the cache\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_model_checkpoint = 'august22_beam_t.ckpt'\n",
    "original_model_checkpoint = 'checkpoint_sep_data_model_state'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = '/home/mohammad.hallaq/workarea/MobileNet_compression/data_h5py_files/sepData_train_P100_N10.h5'\n",
    "# # val_data = '/home/mohammad.hallaq/workarea/MobileNet_compression/data_h5py_files/sepData_test_P100_N10.h5'\n",
    "# test_data = '/home/mohammad.hallaq/workarea/MobileNet_compression/data_h5py_files/sepData_test_P100_N10.h5'\n",
    "# checkpoint_dir = '/home/mohammad.hallaq/workarea/MobileNet_compression/checkpoints'\n",
    "# checkpoint_filename = os.path.join(checkpoint_dir, 'r22_sept15.ckpt')\n",
    "# checkpoint =torch.load(checkpoint_filename)\n",
    "# # checkpoint_dir = '/home/mohammad.hallaq/workarea/MobileNet_compression/sep_dataset_checkpoint'\n",
    "# # checkpoint_filename = os.path.join(checkpoint_dir, 'checkpoint_sep_data_model_state.ckpt')\n",
    "# # checkpoint =torch.load(checkpoint_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_length = 4096\n",
    "batch_size = 256\n",
    "epochs =30\n",
    "\n",
    "hparams = {\n",
    "    'drop_path_rate': 0.2,\n",
    "    'drop_rate': 0.7,\n",
    "    'learning_rate': 1e-3,\n",
    "    'wd': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model_with_pruning(trained_model, pruning_method, model_name_suffix, train_loader, val_loader, prune_amount):\n",
    "#     checkpoint_filename = f\"pruning_results/model_pruned_{model_name_suffix}_amount_{prune_amount}.ckpt\"\n",
    "#     final_model_path = f'pruning_results/model_final_pruned_{model_name_suffix}_amount_{prune_amount}.pth'\n",
    "\n",
    "   \n",
    "#     if os.path.exists(checkpoint_filename) or os.path.exists(final_model_path):\n",
    "#         print(f\"Model {model_name_suffix} at {prune_amount * 100}% pruning already exists. Skipping training.\")\n",
    "#         return\n",
    "\n",
    "#     pruned_model = prune_model(trained_model, pruning_method, prune_amount, train_loader)\n",
    "\n",
    "#     rf_classifier = RFClassifier(pruned_model)\n",
    "\n",
    "#     checkpoint_callback = L.callbacks.ModelCheckpoint(\n",
    "#         dirpath='.',\n",
    "#         filename=checkpoint_filename.replace(\".ckpt\", \"\"),\n",
    "#         save_top_k=1,\n",
    "#         verbose=True,\n",
    "#         monitor='val_loss',\n",
    "#         mode='min'\n",
    "#     )\n",
    "    \n",
    "#     # Create the custom callback\n",
    "#     custom_checkpoint = CustomCheckpoint()\n",
    "\n",
    "#     trainer = L.Trainer(\n",
    "#         max_epochs=30,\n",
    "#         callbacks=[checkpoint_callback, custom_checkpoint],\n",
    "#         accelerator='gpu',\n",
    "#         devices=[3],\n",
    "#         benchmark=True,\n",
    "#         precision='32-true',\n",
    "#     )\n",
    "\n",
    "#     print(f\"Training the model with {pruning_method} applied at {prune_amount * 100}%...\")\n",
    "#     trainer.fit(rf_classifier, train_loader, val_loader)\n",
    "\n",
    "#     torch.save(rf_classifier.model, final_model_path)\n",
    "\n",
    "#     print(f\"Model {pruning_method} at {prune_amount * 100}% pruning saved. \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = '/home/mohammad.hallaq/workarea/AoA-Pruning/data_h5py_files/r22_train.h5'\n",
    "# val_data = '/home/mohammad.hallaq/workarea/AoA-Pruning/data_h5py_files/r22_test.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_length = 4096\n",
    "# batch_size = 128\n",
    "# epochs =30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 98120 examples\n",
      "Testing Set: 45980 examples\n"
     ]
    }
   ],
   "source": [
    "# train_data = '/shared/sepData_train.h5'\n",
    "# val_data = '/shared/sepData_val.h5'\n",
    "# test_data = '/shared/sepData_test.h5'\n",
    "train_data = '/home/mohammad.hallaq/workarea/MobileNet_compression/data_h5py_files/sepData_train_P100_N10.h5'\n",
    "# val_data = '/home/mohammad.hallaq/workarea/MobileNet_compression/data_h5py_files/sepData_test_P100_N10.h5'\n",
    "test_data = '/home/mohammad.hallaq/workarea/MobileNet_compression/data_h5py_files/sepData_test_P100_N10.h5'\n",
    "\n",
    "train_set = R22_H5_Dataset(train_data)\n",
    "# val_set = R22_H5_Dataset(val_data)\n",
    "test_set = R22_H5_Dataset(test_data)\n",
    "print(f'Training Set: {len(train_set)} examples')\n",
    "# print(f'Validation Set: {len(val_set)} examples')\n",
    "print(f'Testing Set: {len(test_set)} examples')\n",
    "\n",
    "num_classes = train_set[0][1].shape[0]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    )\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     dataset=val_set,\n",
    "#     batch_size=128,\n",
    "#     shuffle=False,\n",
    "#     num_workers=8\n",
    "#     )\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = mobilenetv3(\n",
    "    model_size='mobilenetv3_small_050',\n",
    "    num_classes=num_classes,\n",
    "    drop_rate=hparams['drop_rate'],\n",
    "    drop_path_rate=hparams['drop_path_rate'],\n",
    "    in_chans=8\n",
    ")\n",
    "\n",
    "# rf_classifier = RFClassifier.load_from_checkpoint(original_model_checkpoint, model=model)\n",
    "\n",
    "# rf_classifier.to('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix_from_state_dict(state_dict, prefix='model.'):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith(prefix):\n",
    "            new_state_dict[k[len(prefix):]] = v\n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint['state_dict'] = remove_prefix_from_state_dict(checkpoint['state_dict'], prefix='model.')\n",
    "\n",
    "original_model.load_state_dict(checkpoint['state_dict'])\n",
    "# checkpoint = remove_prefix_from_state_dict(checkpoint, prefix='model.')\n",
    "\n",
    "# original_model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Elsayed pre-trained model\n",
    "\n",
    "original_model = original_model.to(general_device)\n",
    "checkpoint = torch.load('/home/mohammad.hallaq/workarea/MobileNet_compression/checkpoints/8oct_mobilenet_sepdata_P20Nmax_noTransform_80epochs_checkpoint_model_state_best.pth', map_location=general_device)\n",
    "original_model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_methods = ['channel_pruning_Taylor_importance']\n",
    "pruning_amounts = [0.95]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "  (0): InvertedResidual(\n",
      "    (conv_pw): Conv1d(7, 40, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): GBN(\n",
      "      (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv_dw): Conv1d(40, 40, kernel_size=(3,), stride=(2,), padding=(1,), groups=40)\n",
      "    (bn2): GBN(\n",
      "      (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (aa): Identity()\n",
      "    (se): Identity()\n",
      "    (conv_pwl): Conv1d(40, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): GBN(\n",
      "      (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Identity()\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.017)\n",
      "  )\n",
      "  (1): InvertedResidual(\n",
      "    (conv_pw): Conv1d(16, 56, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): GBN(\n",
      "      (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv_dw): Conv1d(56, 56, kernel_size=(3,), stride=(1,), padding=(1,), groups=56)\n",
      "    (bn2): GBN(\n",
      "      (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (aa): Identity()\n",
      "    (se): Identity()\n",
      "    (conv_pwl): Conv1d(56, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): GBN(\n",
      "      (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Identity()\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.033)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv_pw): Conv1d(7, 40, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv_dw): Conv1d(40, 40, kernel_size=(3,), stride=(2,), padding=(1,), groups=40)\n",
      "  (bn2): GBN(\n",
      "    (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (aa): Identity()\n",
      "  (se): Identity()\n",
      "  (conv_pwl): Conv1d(40, 16, kernel_size=(1,), stride=(1,))\n",
      "  (bn3): GBN(\n",
      "    (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Identity()\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.017)\n",
      "), Conv1d(7, 40, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): ReLU(inplace=True)\n",
      "), BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), ReLU(inplace=True), Conv1d(40, 40, kernel_size=(3,), stride=(2,), padding=(1,), groups=40), GBN(\n",
      "  (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): ReLU(inplace=True)\n",
      "), BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), ReLU(inplace=True), Identity(), Identity(), Conv1d(40, 16, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Identity()\n",
      "), BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Identity(), DropPath(drop_prob=0.017), InvertedResidual(\n",
      "  (conv_pw): Conv1d(16, 56, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv_dw): Conv1d(56, 56, kernel_size=(3,), stride=(1,), padding=(1,), groups=56)\n",
      "  (bn2): GBN(\n",
      "    (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): ReLU(inplace=True)\n",
      "  )\n",
      "  (aa): Identity()\n",
      "  (se): Identity()\n",
      "  (conv_pwl): Conv1d(56, 16, kernel_size=(1,), stride=(1,))\n",
      "  (bn3): GBN(\n",
      "    (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Identity()\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.033)\n",
      "), Conv1d(16, 56, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): ReLU(inplace=True)\n",
      "), BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), ReLU(inplace=True), Conv1d(56, 56, kernel_size=(3,), stride=(1,), padding=(1,), groups=56), GBN(\n",
      "  (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): ReLU(inplace=True)\n",
      "), BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), ReLU(inplace=True), Identity(), Identity(), Conv1d(56, 16, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Identity()\n",
      "), BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Identity(), DropPath(drop_prob=0.033), Sequential(\n",
      "  (0): InvertedResidual(\n",
      "    (conv_pw): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): GBN(\n",
      "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (conv_dw): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), groups=64)\n",
      "    (bn2): GBN(\n",
      "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (aa): Identity()\n",
      "    (se): SqueezeExcite(\n",
      "      (conv_reduce): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "      (act1): SiLU(inplace=True)\n",
      "      (conv_expand): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (conv_pwl): Conv1d(64, 24, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): GBN(\n",
      "      (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Identity()\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.050)\n",
      "  )\n",
      "  (1): InvertedResidual(\n",
      "    (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): GBN(\n",
      "      (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
      "    (bn2): GBN(\n",
      "      (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (aa): Identity()\n",
      "    (se): SqueezeExcite(\n",
      "      (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "      (act1): SiLU(inplace=True)\n",
      "      (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): GBN(\n",
      "      (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Identity()\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.067)\n",
      "  )\n",
      "  (2): InvertedResidual(\n",
      "    (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): GBN(\n",
      "      (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
      "    (bn2): GBN(\n",
      "      (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (aa): Identity()\n",
      "    (se): SqueezeExcite(\n",
      "      (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "      (act1): SiLU(inplace=True)\n",
      "      (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): GBN(\n",
      "      (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Identity()\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.083)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv_pw): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (conv_dw): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), groups=64)\n",
      "  (bn2): GBN(\n",
      "    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (aa): Identity()\n",
      "  (se): SqueezeExcite(\n",
      "    (conv_reduce): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (act1): SiLU(inplace=True)\n",
      "    (conv_expand): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (conv_pwl): Conv1d(64, 24, kernel_size=(1,), stride=(1,))\n",
      "  (bn3): GBN(\n",
      "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Identity()\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.050)\n",
      "), Conv1d(16, 64, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), groups=64), GBN(\n",
      "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Identity(), SqueezeExcite(\n",
      "  (conv_reduce): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "  (act1): SiLU(inplace=True)\n",
      "  (conv_expand): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "), Conv1d(64, 16, kernel_size=(1,), stride=(1,)), SiLU(inplace=True), Conv1d(16, 64, kernel_size=(1,), stride=(1,)), Conv1d(64, 24, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Identity()\n",
      "), BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Identity(), DropPath(drop_prob=0.050), InvertedResidual(\n",
      "  (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
      "  (bn2): GBN(\n",
      "    (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (aa): Identity()\n",
      "  (se): SqueezeExcite(\n",
      "    (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "    (act1): SiLU(inplace=True)\n",
      "    (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
      "  (bn3): GBN(\n",
      "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Identity()\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.067)\n",
      "), Conv1d(24, 144, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144), GBN(\n",
      "  (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Identity(), SqueezeExcite(\n",
      "  (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "  (act1): SiLU(inplace=True)\n",
      "  (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "), Conv1d(144, 40, kernel_size=(1,), stride=(1,)), SiLU(inplace=True), Conv1d(40, 144, kernel_size=(1,), stride=(1,)), Conv1d(144, 24, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Identity()\n",
      "), BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Identity(), DropPath(drop_prob=0.067), InvertedResidual(\n",
      "  (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
      "  (bn2): GBN(\n",
      "    (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (aa): Identity()\n",
      "  (se): SqueezeExcite(\n",
      "    (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "    (act1): SiLU(inplace=True)\n",
      "    (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
      "  (bn3): GBN(\n",
      "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Identity()\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.083)\n",
      "), Conv1d(24, 144, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144), GBN(\n",
      "  (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Identity(), SqueezeExcite(\n",
      "  (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "  (act1): SiLU(inplace=True)\n",
      "  (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "), Conv1d(144, 40, kernel_size=(1,), stride=(1,)), SiLU(inplace=True), Conv1d(40, 144, kernel_size=(1,), stride=(1,)), Conv1d(144, 24, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Identity()\n",
      "), BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Identity(), DropPath(drop_prob=0.083), Sequential(\n",
      "  (0): InvertedResidual(\n",
      "    (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): GBN(\n",
      "      (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
      "    (bn2): GBN(\n",
      "      (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (aa): Identity()\n",
      "    (se): SqueezeExcite(\n",
      "      (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "      (act1): SiLU(inplace=True)\n",
      "      (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): GBN(\n",
      "      (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Identity()\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.100)\n",
      "  )\n",
      "  (1): InvertedResidual(\n",
      "    (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): GBN(\n",
      "      (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
      "    (bn2): GBN(\n",
      "      (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (aa): Identity()\n",
      "    (se): SqueezeExcite(\n",
      "      (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "      (act1): SiLU(inplace=True)\n",
      "      (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): GBN(\n",
      "      (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Identity()\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.117)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
      "  (bn2): GBN(\n",
      "    (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (aa): Identity()\n",
      "  (se): SqueezeExcite(\n",
      "    (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "    (act1): SiLU(inplace=True)\n",
      "    (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "  (bn3): GBN(\n",
      "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Identity()\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.100)\n",
      "), Conv1d(24, 72, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72), GBN(\n",
      "  (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Identity(), SqueezeExcite(\n",
      "  (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "  (act1): SiLU(inplace=True)\n",
      "  (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "), Conv1d(72, 24, kernel_size=(1,), stride=(1,)), SiLU(inplace=True), Conv1d(24, 72, kernel_size=(1,), stride=(1,)), Conv1d(72, 24, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Identity()\n",
      "), BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Identity(), DropPath(drop_prob=0.100), InvertedResidual(\n",
      "  (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
      "  (bn2): GBN(\n",
      "    (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (aa): Identity()\n",
      "  (se): SqueezeExcite(\n",
      "    (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "    (act1): SiLU(inplace=True)\n",
      "    (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "  (bn3): GBN(\n",
      "    (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Identity()\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.117)\n",
      "), Conv1d(24, 72, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72), GBN(\n",
      "  (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Identity(), SqueezeExcite(\n",
      "  (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "  (act1): SiLU(inplace=True)\n",
      "  (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "), Conv1d(72, 24, kernel_size=(1,), stride=(1,)), SiLU(inplace=True), Conv1d(24, 72, kernel_size=(1,), stride=(1,)), Conv1d(72, 24, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Identity()\n",
      "), BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Identity(), DropPath(drop_prob=0.117), Sequential(\n",
      "  (0): InvertedResidual(\n",
      "    (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): GBN(\n",
      "      (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(2,), padding=(2,), groups=144)\n",
      "    (bn2): GBN(\n",
      "      (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (aa): Identity()\n",
      "    (se): SqueezeExcite(\n",
      "      (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "      (act1): SiLU(inplace=True)\n",
      "      (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (conv_pwl): Conv1d(144, 48, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): GBN(\n",
      "      (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Identity()\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.133)\n",
      "  )\n",
      "  (1): InvertedResidual(\n",
      "    (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): GBN(\n",
      "      (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
      "    (bn2): GBN(\n",
      "      (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (aa): Identity()\n",
      "    (se): SqueezeExcite(\n",
      "      (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "      (act1): SiLU(inplace=True)\n",
      "      (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): GBN(\n",
      "      (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Identity()\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.150)\n",
      "  )\n",
      "  (2): InvertedResidual(\n",
      "    (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): GBN(\n",
      "      (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
      "    (bn2): GBN(\n",
      "      (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (aa): Identity()\n",
      "    (se): SqueezeExcite(\n",
      "      (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "      (act1): SiLU(inplace=True)\n",
      "      (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): GBN(\n",
      "      (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Identity()\n",
      "    )\n",
      "    (drop_path): DropPath(drop_prob=0.167)\n",
      "  )\n",
      "), InvertedResidual(\n",
      "  (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(2,), padding=(2,), groups=144)\n",
      "  (bn2): GBN(\n",
      "    (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (aa): Identity()\n",
      "  (se): SqueezeExcite(\n",
      "    (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "    (act1): SiLU(inplace=True)\n",
      "    (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (conv_pwl): Conv1d(144, 48, kernel_size=(1,), stride=(1,))\n",
      "  (bn3): GBN(\n",
      "    (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Identity()\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.133)\n",
      "), Conv1d(24, 144, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Conv1d(144, 144, kernel_size=(5,), stride=(2,), padding=(2,), groups=144), GBN(\n",
      "  (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Identity(), SqueezeExcite(\n",
      "  (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "  (act1): SiLU(inplace=True)\n",
      "  (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "), Conv1d(144, 40, kernel_size=(1,), stride=(1,)), SiLU(inplace=True), Conv1d(40, 144, kernel_size=(1,), stride=(1,)), Conv1d(144, 48, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Identity()\n",
      "), BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Identity(), DropPath(drop_prob=0.133), InvertedResidual(\n",
      "  (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
      "  (bn2): GBN(\n",
      "    (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (aa): Identity()\n",
      "  (se): SqueezeExcite(\n",
      "    (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "    (act1): SiLU(inplace=True)\n",
      "    (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
      "  (bn3): GBN(\n",
      "    (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Identity()\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.150)\n",
      "), Conv1d(48, 288, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288), GBN(\n",
      "  (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Identity(), SqueezeExcite(\n",
      "  (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "  (act1): SiLU(inplace=True)\n",
      "  (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "), Conv1d(288, 72, kernel_size=(1,), stride=(1,)), SiLU(inplace=True), Conv1d(72, 288, kernel_size=(1,), stride=(1,)), Conv1d(288, 48, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Identity()\n",
      "), BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Identity(), DropPath(drop_prob=0.150), InvertedResidual(\n",
      "  (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
      "  (bn2): GBN(\n",
      "    (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (aa): Identity()\n",
      "  (se): SqueezeExcite(\n",
      "    (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "    (act1): SiLU(inplace=True)\n",
      "    (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
      "  (bn3): GBN(\n",
      "    (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Identity()\n",
      "  )\n",
      "  (drop_path): DropPath(drop_prob=0.167)\n",
      "), Conv1d(48, 288, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288), GBN(\n",
      "  (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Identity(), SqueezeExcite(\n",
      "  (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "  (act1): SiLU(inplace=True)\n",
      "  (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "), Conv1d(288, 72, kernel_size=(1,), stride=(1,)), SiLU(inplace=True), Conv1d(72, 288, kernel_size=(1,), stride=(1,)), Conv1d(288, 48, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Identity()\n",
      "), BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Identity(), DropPath(drop_prob=0.167), Sequential(\n",
      "  (0): ConvBnAct(\n",
      "    (conv): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): GBN(\n",
      "      (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Identity()\n",
      "      (act): Hardswish()\n",
      "    )\n",
      "    (aa): Identity()\n",
      "    (drop_path): DropPath(drop_prob=0.183)\n",
      "  )\n",
      "), ConvBnAct(\n",
      "  (conv): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (aa): Identity()\n",
      "  (drop_path): DropPath(drop_prob=0.183)\n",
      "), Conv1d(48, 288, kernel_size=(1,), stride=(1,)), GBN(\n",
      "  (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Identity()\n",
      "  (act): Hardswish()\n",
      "), BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Identity(), Hardswish(), Identity(), DropPath(drop_prob=0.183), Linear(in_features=972, out_features=2, bias=True)]\n",
      "MACs: 0.023294524 G, #Params: 533.203 K\n"
     ]
    }
   ],
   "source": [
    "pruned_model = prune_model(original_model, pruning_methods[0], pruning_amounts[0], train_loader)\n",
    "# Free up cached memory\n",
    "torch.cuda.empty_cache()\n",
    "example_inputs = torch.randn(1, 8, 4096)\n",
    "example_inputs = example_inputs.to(general_device)  \n",
    "macs, nparams = tp.utils.count_ops_and_params(pruned_model, example_inputs)\n",
    "print(f\"MACs: {macs/1e9} G, #Params: {nparams/1e3} K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in pruning_methods:\n",
    "    for amount in pruning_amounts:\n",
    "        train_model_with_pruning(original_model, method, method, train_loader, val_loader, amount)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating The Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = torch.load('/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/best_model.pth')\n",
    "# example_inputs = torch.randn(1, 8, 4096)\n",
    "# example_inputs = example_inputs.to(general_device)  \n",
    "# macs, nparams = tp.utils.count_ops_and_params(pruned_model, example_inputs)\n",
    "# print(f\"MACs: {macs/1e9} G, #Params: {nparams/1e3} K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d603fdc89649cd9f02534febb68477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">        Test metric        </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span><span style=\"color: #800080; text-decoration-color: #800080\">    17.421855926513672     </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m   17.421855926513672    \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 17.421855926513672}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier = RFClassifier(pruned_model)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=1,\n",
    "    accelerator='gpu',\n",
    "    devices=[3],\n",
    "    benchmark=True,\n",
    "    precision='32-true',\n",
    ")\n",
    "\n",
    "trainer.test(rf_classifier, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quiver(all_targets, all_outputs, quiver_path: str):\n",
    "    \"\"\"\n",
    "    Creates and stores the quiver plot for given targets and predicted outputs\n",
    "    :args all_targets:\n",
    "    :args all_outputs:\n",
    "    \"\"\"\n",
    "    predictions_per_target = defaultdict(list)\n",
    "    errors_per_target = dict()\n",
    "\n",
    "    for idx, target_angles_tuple in enumerate(all_targets):\n",
    "        target_tuple = tuple(target_angles_tuple)\n",
    "        predictions_per_target[target_tuple].append(all_outputs[idx])\n",
    "    for target_tuple, list_of_predictions in predictions_per_target.items():\n",
    "        # predictions_per_target[target_tuple] = np.mean(list_of_predictions, axis=0)\n",
    "        errors_per_target[target_tuple] = np.subtract(target_tuple, np.mean(list_of_predictions, axis=0))\n",
    "\n",
    "    unique_targets = list(errors_per_target.keys())\n",
    "    unique_azimuth = [target[0] for target in unique_targets]\n",
    "    unique_elevation = [target[1] for target in unique_targets]\n",
    "    unique_erros = list(errors_per_target.values())\n",
    "    errors_azimuth = [target[0] for target in unique_erros]\n",
    "    errors_elevation = [target[1] for target in unique_erros]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(unique_azimuth, unique_elevation, color='red', label='True Angles')\n",
    "    plt.quiver(unique_azimuth, unique_elevation, errors_azimuth, errors_elevation,\n",
    "                angles='xy', scale_units='xy', scale=1, color='blue', label='Predicted Angles')\n",
    "    plt.xlim([-55, 55])\n",
    "    plt.ylim([-55, 55])\n",
    "    plt.xlabel('Azimuth')\n",
    "    plt.ylabel('Elevation')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.savefig(quiver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 384/384 [00:19<00:00, 19.97batch/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_model.eval()\n",
    "test_loss = 0\n",
    "all_targets, all_outputs = np.zeros([1, 2]), np.zeros([1, 2])\n",
    "device = general_device\n",
    "experiment_path = '/home/mohammad.hallaq/workarea/AoA-Pruning/experiments'\n",
    "original_model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(train_loader, desc='Training', unit='batch') as pbar:\n",
    "        for sample_inputs, targets in pbar:\n",
    "            sample_inputs = sample_inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = original_model(sample_inputs)\n",
    "            all_targets = np.concatenate((all_targets, targets.cpu()))\n",
    "            all_outputs = np.concatenate((all_outputs, outputs.cpu()))           \n",
    "    all_outputs = all_outputs[1:]\n",
    "    all_targets = all_targets[1:]\n",
    "    quiver_path = os.path.join(experiment_path, \"training_quiver_plot.png\")\n",
    "    plot_quiver(all_targets, all_outputs, quiver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|| 360/360 [00:12<00:00, 28.59batch/s, Val Loss=0.604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Loss = 0.0016785163691210333\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "experiment_path = '/home/mohammad.hallaq/workarea/AoA-Pruning/experiments'\n",
    "device = general_device\n",
    "original_model = original_model.to(device)\n",
    "original_model.eval()\n",
    "eval_values = {'azimuth_true': [], 'azimuth_pred': [], 'elevation_true': [], 'elevation_pred': [], 'loss_value': []}\n",
    "\n",
    "test_loss, num_samples = 0, 0\n",
    "all_targets, all_outputs = np.zeros([1, 2]), np.zeros([1, 2])\n",
    "with torch.no_grad():\n",
    "    with tqdm(test_loader, desc='Testing', unit='batch') as pbar:\n",
    "        for sample_inputs, targets in pbar:\n",
    "            sample_inputs = sample_inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = original_model(sample_inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            eval_values['azimuth_pred'] = targets\n",
    "            num_samples += targets.shape[0]\n",
    "            test_loss += loss.item()/num_samples\n",
    "            all_targets = np.concatenate((all_targets, targets.cpu()))\n",
    "            all_outputs = np.concatenate((all_outputs, outputs.cpu()))\n",
    "            pbar.set_postfix({'Val Loss': test_loss})\n",
    "    all_outputs = all_outputs[1:]\n",
    "    all_targets = all_targets[1:]\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    print(f\"Test Set Loss = {test_loss}\")\n",
    "    quiver_path = os.path.join(experiment_path, \"testing_quiver_plot.png\")\n",
    "    plot_quiver(all_targets, all_outputs, quiver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|| 360/360 [00:08<00:00, 44.10batch/s, Val MSE Loss=0.819, Val MAE Loss=0.157]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set MSE Loss = 0.002274470876823534\n",
      "Test Set MAE Loss = 0.0004351161149464336\n",
      "Azimuth MSE Loss by Angle: {-50: 9.322987003475694, -40: 10.776542919187596, -30: 18.10026383387895, -20: 16.549456863433246, -10: 21.514832795244196, 0: 24.590908095654108, 10: 30.98614140927396, 20: 22.04925998076995, 30: 20.074403589034393, 40: 22.30198700478166, 50: 16.003716161277318}\n",
      "Elevation MSE Loss by Angle: {-50: 35.8180826386433, -40: 22.175420807542015, -30: 11.741761853081524, -20: 11.329170238164249, -10: 19.350799122395102, 0: 15.990523159724658, 10: 17.04793549554149, 20: 21.52940815298188, 30: 21.655838746416364, 40: 25.442287274968784, 50: 66.68810925520035}\n",
      "Azimuth MAE Loss by Angle: {-50: 2.233998483137651, -40: 2.6764619728826706, -30: 3.1563948870334273, -20: 3.0150144710097204, -10: 3.559504486188828, 0: 3.937448875905343, 10: 4.269344477220015, 20: 3.8278021916811045, 30: 3.6294917214471853, 40: 3.962026115834288, 50: 3.006088425853465}\n",
      "Elevation MAE Loss by Angle: {-50: 5.02669110267785, -40: 3.9545744757319605, -30: 2.6565101571473533, -20: 2.5794153689312678, -10: 3.2526510175136383, 0: 3.0055980592903073, 10: 3.1135095181979286, 20: 3.5102697565994103, 30: 3.70218284296435, 40: 3.97842503516122, 50: 7.17859374611241}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define both MSE and MAE criteria\n",
    "mse_criterion = nn.MSELoss()\n",
    "mae_criterion = nn.L1Loss()\n",
    "\n",
    "device = general_device\n",
    "pruned_model = pruned_model.to(device)\n",
    "pruned_model.eval()\n",
    "\n",
    "# Initialize dictionaries to accumulate MSE and MAE losses for each angle\n",
    "angle_loss_accumulation = {\n",
    "    'azimuth_mse': {angle: 0.0 for angle in range(-50, 60, 10)},\n",
    "    'elevation_mse': {angle: 0.0 for angle in range(-50, 60, 10)},\n",
    "    'azimuth_mae': {angle: 0.0 for angle in range(-50, 60, 10)},\n",
    "    'elevation_mae': {angle: 0.0 for angle in range(-50, 60, 10)},\n",
    "    'azimuth_count': {angle: 0 for angle in range(-50, 60, 10)},\n",
    "    'elevation_count': {angle: 0 for angle in range(-50, 60, 10)}\n",
    "}\n",
    "\n",
    "test_mse, test_mae, num_samples = 0, 0, 0\n",
    "all_targets, all_outputs = np.zeros([1, 2]), np.zeros([1, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(test_loader, desc='Testing', unit='batch') as pbar:\n",
    "        for sample_inputs, targets in pbar:\n",
    "            sample_inputs = sample_inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = pruned_model(sample_inputs)\n",
    "            \n",
    "            # Calculate losses for this batch\n",
    "            mse_loss = mse_criterion(outputs, targets)\n",
    "            mae_loss = mae_criterion(outputs, targets)\n",
    "            num_samples += targets.shape[0]\n",
    "\n",
    "            test_mse += mse_loss.item() / num_samples\n",
    "            test_mae += mae_loss.item() / num_samples\n",
    "\n",
    "            # Convert to CPU and detach for evaluation\n",
    "            outputs_np = outputs.cpu().numpy()\n",
    "            targets_np = targets.cpu().numpy()\n",
    "\n",
    "            # Accumulate MSE and MAE losses for each angle\n",
    "            for i in range(targets_np.shape[0]):\n",
    "                true_azimuth, true_elevation = targets_np[i]\n",
    "                pred_azimuth, pred_elevation = outputs_np[i]\n",
    "\n",
    "                azimuth_mse = (pred_azimuth - true_azimuth) ** 2\n",
    "                elevation_mse = (pred_elevation - true_elevation) ** 2\n",
    "\n",
    "                azimuth_mae = abs(pred_azimuth - true_azimuth)\n",
    "                elevation_mae = abs(pred_elevation - true_elevation)\n",
    "\n",
    "                # Accumulate losses for each azimuth and elevation value\n",
    "                angle_loss_accumulation['azimuth_mse'][int(true_azimuth)] += azimuth_mse\n",
    "                angle_loss_accumulation['elevation_mse'][int(true_elevation)] += elevation_mse\n",
    "                angle_loss_accumulation['azimuth_mae'][int(true_azimuth)] += azimuth_mae\n",
    "                angle_loss_accumulation['elevation_mae'][int(true_elevation)] += elevation_mae\n",
    "\n",
    "                # Count occurrences of each azimuth and elevation value\n",
    "                angle_loss_accumulation['azimuth_count'][int(true_azimuth)] += 1\n",
    "                angle_loss_accumulation['elevation_count'][int(true_elevation)] += 1\n",
    "\n",
    "            all_targets = np.concatenate((all_targets, targets_np))\n",
    "            all_outputs = np.concatenate((all_outputs, outputs_np))\n",
    "\n",
    "            pbar.set_postfix({'Val MSE Loss': test_mse, 'Val MAE Loss': test_mae})\n",
    "\n",
    "    all_outputs = all_outputs[1:]\n",
    "    all_targets = all_targets[1:]\n",
    "    test_mse = test_mse / len(test_loader)\n",
    "    test_mae = test_mae / len(test_loader)\n",
    "\n",
    "    # Calculate average MSE and MAE loss per angle\n",
    "    avg_azimuth_mse, avg_elevation_mse = {}, {}\n",
    "    avg_azimuth_mae, avg_elevation_mae = {}, {}\n",
    "\n",
    "    for angle in range(-50, 60, 10):\n",
    "        if angle_loss_accumulation['azimuth_count'][angle] > 0:\n",
    "            avg_azimuth_mse[angle] = angle_loss_accumulation['azimuth_mse'][angle] / angle_loss_accumulation['azimuth_count'][angle]\n",
    "            avg_azimuth_mae[angle] = angle_loss_accumulation['azimuth_mae'][angle] / angle_loss_accumulation['azimuth_count'][angle]\n",
    "        else:\n",
    "            avg_azimuth_mse[angle] = 0.0\n",
    "            avg_azimuth_mae[angle] = 0.0\n",
    "\n",
    "        if angle_loss_accumulation['elevation_count'][angle] > 0:\n",
    "            avg_elevation_mse[angle] = angle_loss_accumulation['elevation_mse'][angle] / angle_loss_accumulation['elevation_count'][angle]\n",
    "            avg_elevation_mae[angle] = angle_loss_accumulation['elevation_mae'][angle] / angle_loss_accumulation['elevation_count'][angle]\n",
    "        else:\n",
    "            avg_elevation_mse[angle] = 0.0\n",
    "            avg_elevation_mae[angle] = 0.0\n",
    "\n",
    "    print(f\"Test Set MSE Loss = {test_mse}\")\n",
    "    print(f\"Test Set MAE Loss = {test_mae}\")\n",
    "    print(f\"Azimuth MSE Loss by Angle: {avg_azimuth_mse}\")\n",
    "    print(f\"Elevation MSE Loss by Angle: {avg_elevation_mse}\")\n",
    "    print(f\"Azimuth MAE Loss by Angle: {avg_azimuth_mae}\")\n",
    "    print(f\"Elevation MAE Loss by Angle: {avg_elevation_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_deviation(loader, model):\n",
    "    device = next(model.parameters()).device\n",
    "    model.to(device)\n",
    "    total_azimuth_deviation = 0\n",
    "    total_elevation_deviation = 0\n",
    "    num_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs, true_angles = batch\n",
    "            inputs, true_angles = inputs.to(device), true_angles.to(device)\n",
    "            predicted = model(inputs).cpu().numpy()\n",
    "            true_angles = true_angles.cpu().numpy()\n",
    "            azimuth_deviation = np.abs(predicted[:, 0] - true_angles[:, 0])\n",
    "            elevation_deviation = np.abs(predicted[:, 1] - true_angles[:, 1])\n",
    "        \n",
    "            total_azimuth_deviation += np.sum(azimuth_deviation)\n",
    "            total_elevation_deviation += np.sum(elevation_deviation)\n",
    "            num_samples += len(true_angles)\n",
    "    avg_azimuth_deviation = total_azimuth_deviation / num_samples\n",
    "    avg_elevation_deviation = total_elevation_deviation / num_samples\n",
    "    return avg_azimuth_deviation, avg_elevation_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4380250465029167 2.6354439758350545\n"
     ]
    }
   ],
   "source": [
    "avg_azim_dev, avg_elev_dev = calculate_average_deviation(val_loader, pruned_model)\n",
    "print(avg_azim_dev, avg_elev_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (conv_stem): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "  (bn1): GBN(\n",
       "    (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop): Identity()\n",
       "    (act): Hardswish()\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv1d(16, 16, kernel_size=(3,), stride=(2,), padding=(1,), groups=16)\n",
       "        (bn1): GBN(\n",
       "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (conv_pw): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
       "        (bn2): GBN(\n",
       "          (bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv1d(8, 40, kernel_size=(1,), stride=(1,))\n",
       "        (bn1): GBN(\n",
       "          (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv1d(40, 40, kernel_size=(3,), stride=(2,), padding=(1,), groups=40)\n",
       "        (bn2): GBN(\n",
       "          (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv1d(40, 16, kernel_size=(1,), stride=(1,))\n",
       "        (bn3): GBN(\n",
       "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.017)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv1d(16, 56, kernel_size=(1,), stride=(1,))\n",
       "        (bn1): GBN(\n",
       "          (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv1d(56, 56, kernel_size=(3,), stride=(1,), padding=(1,), groups=56)\n",
       "        (bn2): GBN(\n",
       "          (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv1d(56, 16, kernel_size=(1,), stride=(1,))\n",
       "        (bn3): GBN(\n",
       "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.033)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
       "        (bn1): GBN(\n",
       "          (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), groups=64)\n",
       "        (bn2): GBN(\n",
       "          (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (conv_pwl): Conv1d(64, 24, kernel_size=(1,), stride=(1,))\n",
       "        (bn3): GBN(\n",
       "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.050)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
       "        (bn1): GBN(\n",
       "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
       "        (bn2): GBN(\n",
       "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
       "        (bn3): GBN(\n",
       "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.067)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
       "        (bn1): GBN(\n",
       "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
       "        (bn2): GBN(\n",
       "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
       "        (bn3): GBN(\n",
       "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.083)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
       "        (bn1): GBN(\n",
       "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
       "        (bn2): GBN(\n",
       "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
       "        (bn3): GBN(\n",
       "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.100)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
       "        (bn1): GBN(\n",
       "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
       "        (bn2): GBN(\n",
       "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
       "        (bn3): GBN(\n",
       "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.117)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
       "        (bn1): GBN(\n",
       "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(2,), padding=(2,), groups=144)\n",
       "        (bn2): GBN(\n",
       "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (conv_pwl): Conv1d(144, 48, kernel_size=(1,), stride=(1,))\n",
       "        (bn3): GBN(\n",
       "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.133)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
       "        (bn1): GBN(\n",
       "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
       "        (bn2): GBN(\n",
       "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
       "        (bn3): GBN(\n",
       "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.150)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
       "        (bn1): GBN(\n",
       "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
       "        (bn2): GBN(\n",
       "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
       "        (bn3): GBN(\n",
       "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.167)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
       "        (bn1): GBN(\n",
       "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (aa): Identity()\n",
       "        (drop_path): DropPath(drop_prob=0.183)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (global_pool): FastGlobalAvgPool1d()\n",
       "  (conv_head): Conv1d(288, 1024, kernel_size=(1,), stride=(1,))\n",
       "  (norm_head): Identity()\n",
       "  (act2): Hardswish()\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_0: 5683433.966796875\n",
      "block_1: 688666.7939453125\n",
      "block_2: 1251886.1856689453\n",
      "block_3: 1059496.609008789\n",
      "block_4: -1107828.1356811523\n",
      "block_5: 16291.169533729553\n"
     ]
    }
   ],
   "source": [
    "class ActivationAggregator:\n",
    "    def __init__(self):\n",
    "        self.activations = {}\n",
    "        self.aggregated_activations = {}\n",
    "\n",
    "    def hook(self, module, input, output, layer_name, block_name):\n",
    "        # Capture individual activations\n",
    "        if layer_name not in self.activations:\n",
    "            self.activations[layer_name] = output.detach().clone()\n",
    "        else:\n",
    "            self.activations[layer_name] += output.detach().clone()\n",
    "        \n",
    "        # Aggregate activations for the block\n",
    "        if block_name not in self.aggregated_activations:\n",
    "            self.aggregated_activations[block_name] = output.detach().clone()\n",
    "        else:\n",
    "            self.aggregated_activations[block_name] += output.detach().clone()\n",
    "\n",
    "    def attach_hooks(self, model):\n",
    "        block_idx = 0\n",
    "        for block in model.blocks:\n",
    "            for i, layer in enumerate(block):\n",
    "                if isinstance(layer, nn.Sequential):\n",
    "                    for j, sub_layer in enumerate(layer):\n",
    "                        layer_name = f\"block_{block_idx}_layer_{i}_sub_layer_{j}\"\n",
    "                        block_name = f\"block_{block_idx}\"\n",
    "                        sub_layer.register_forward_hook(\n",
    "                            lambda mod, inp, out, name=layer_name, block=block_name: self.hook(mod, inp, out, name, block)\n",
    "                        )\n",
    "                else:\n",
    "                    layer_name = f\"block_{block_idx}_layer_{i}\"\n",
    "                    block_name = f\"block_{block_idx}\"\n",
    "                    layer.register_forward_hook(\n",
    "                        lambda mod, inp, out, name=layer_name, block=block_name: self.hook(mod, inp, out, name, block)\n",
    "                    )\n",
    "            block_idx += 1\n",
    "\n",
    "    def clear_activations(self):\n",
    "        # Clear individual activations and aggregated activations after each forward pass\n",
    "        self.activations = {}\n",
    "        self.aggregated_activations = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = original_model  \n",
    "aggregator = ActivationAggregator()\n",
    "\n",
    "# Attach hooks to the model\n",
    "aggregator.attach_hooks(model)\n",
    "\n",
    "scores = {}  # To store the aggregated scores for each block across batches\n",
    "\n",
    "# Initialize the scores dictionary with 0 for each block\n",
    "for block_name in [f\"block_{i}\" for i in range(len(model.blocks))]:\n",
    "    scores[block_name] = 0.0\n",
    "\n",
    "# Loop through the test data loader\n",
    "for i, (input, target) in enumerate(test_loader):\n",
    "    input = input.to(general_device)\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    model(input)\n",
    "\n",
    "    # Aggregate activations per block for the current batch\n",
    "    for block_name, activation in aggregator.aggregated_activations.items():\n",
    "        # Perform the aggregation (sum and mean) for each block\n",
    "        aggregated_value = torch.mean(torch.sum(torch.sum(activation, dim=0), dim=1))\n",
    "        \n",
    "        # Accumulate scores across batches\n",
    "        scores[block_name] += aggregated_value.item()\n",
    "\n",
    "    # Clear activations for the next batch\n",
    "    aggregator.clear_activations()\n",
    "\n",
    "# Print the final accumulated scores for each block\n",
    "for block_name, score in scores.items():\n",
    "    print(f\"{block_name}: {score}\")\n",
    "    \n",
    "# # Forward pass (with a dummy input of shape [batch_size, 8, 4096])\n",
    "# x,_ = next(iter(train_loader))\n",
    "# # x = x[0].unsqueeze(0)\n",
    "# x = x.to(general_device)\n",
    "\n",
    "# model(x)\n",
    "\n",
    "# # Access individual layer activations\n",
    "# print(\"Individual Layer Activations:\")\n",
    "# for layer_name, activation in aggregator.activations.items():\n",
    "#     print(f\"{layer_name}: {torch.mean(activation)}\")\n",
    "\n",
    "# # Access aggregated activations for each block\n",
    "# print(\"\\nAggregated Activations per Block:\")\n",
    "# for block_name, activation in aggregator.aggregated_activations.items():\n",
    "#     print(f\"{block_name}: {torch.mean(torch.sum(torch.sum(activation, dim=0), dim=1))}\")\n",
    "\n",
    "# # Clear activations if needed for the next forward pass\n",
    "# aggregator.clear_activations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_0: 5.683433966796875\n",
      "block_1: 0.6886667939453125\n",
      "block_2: 1.2518861856689454\n",
      "block_3: 1.0594966090087892\n",
      "block_4: -1.1078281356811523\n",
      "block_5: 0.016291169533729555\n"
     ]
    }
   ],
   "source": [
    "for block_name, score in scores.items():\n",
    "    print(f\"{block_name}: {score/1e6}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 40, 64, 72, 144, 288]\n"
     ]
    }
   ],
   "source": [
    "def get_first_layer_output_channels(model):\n",
    "    output_channels = []\n",
    "\n",
    "    for _, module in model.named_modules():\n",
    "        if isinstance(module, nn.Sequential):\n",
    "            for _, sub_module in module.named_children():\n",
    "                for _, layer in sub_module.named_children():\n",
    "                    if isinstance(layer, nn.Conv1d):\n",
    "                        output_channels.append(layer.out_channels)\n",
    "                        break  # Exit after the first Conv1d layer\n",
    "                break  # Exit after inspecting the first block in Sequential\n",
    "\n",
    "    return output_channels\n",
    "\n",
    "# Assuming `mobilenet_v3` is your model instance\n",
    "output_channels = get_first_layer_output_channels(original_model)\n",
    "print(output_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning ratio here is:  0.93\n",
      "MACs: 0.022379553 G, #Params: 547.612 K\n",
      "Pruning ratio here is:  0.0\n",
      "MACs: 0.022379553 G, #Params: 547.612 K\n",
      "Pruning ratio here is:  0.0\n",
      "MACs: 0.022379553 G, #Params: 547.612 K\n",
      "Pruning ratio here is:  0.0\n",
      "MACs: 0.022379553 G, #Params: 547.612 K\n",
      "Pruning ratio here is:  0.0\n",
      "MACs: 0.022379553 G, #Params: 547.612 K\n",
      "Pruning ratio here is:  0.0\n",
      "MACs: 0.022379553 G, #Params: 547.612 K\n"
     ]
    }
   ],
   "source": [
    "model =  copy.deepcopy(original_model)\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "x, y = batch\n",
    "x,y = x.to(device), y.to(device)\n",
    "imp = tp.importance.TaylorImportance()\n",
    "\n",
    "output_channels = get_first_layer_output_channels(model)\n",
    "\n",
    "\n",
    "pruning_ratios = [0.93, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "pruning_info = {\n",
    "    i: {\"block\": model.blocks[i], \"pruning_ratio\": ratio}\n",
    "    for i, ratio in enumerate(pruning_ratios)\n",
    "}\n",
    "\n",
    "if isinstance(imp, tp.importance.TaylorImportance):\n",
    "    y_hat = model(x)\n",
    "    loss = F.mse_loss(y_hat, y)\n",
    "    loss.backward()\n",
    "\n",
    "# First, collect the layers to be ignored (conv_stem, bn1, and classifier)\n",
    "ignored_layers = [\n",
    "    # model.conv_stem, \n",
    "    # model.bn1,\n",
    "    model.global_pool,\n",
    "    model.conv_head,\n",
    "    model.norm_head,\n",
    "    model.act2,\n",
    "    model.flatten,\n",
    "    model.classifier\n",
    "]\n",
    "\n",
    "# ignored_layers_group = []\n",
    "# Iterate through the named modules of the model to add layers to be ignored\n",
    "# for name, m in original_model.named_modules():\n",
    "#     # Add layers from Sequential(3), Sequential(4), Sequential(5) and the classifier\n",
    "#     if (isinstance(m, torch.nn.Linear) and m.out_features == 2):\n",
    "#         ignored_layers_group.append(m)\n",
    "\n",
    "# Example usage for pruning while ignoring other blocks\n",
    "for i, info in pruning_info.items():\n",
    "    block_to_prune = info[\"block\"]\n",
    "    pruning_ratio = info[\"pruning_ratio\"]\n",
    "    \n",
    "    # # Now add all other blocks to ignored layers except the current block to be pruned\n",
    "    # for j, block in enumerate(model.blocks):\n",
    "    #     if block != block_to_prune:\n",
    "    #         ignored_layers_group.append(block)\n",
    "\n",
    "    # Dynamically ignore other blocks except the current block to prune\n",
    "    ignored_layers_block = [pruning_info[j][\"block\"] for j in range(len(pruning_info)) if j != i]\n",
    "\n",
    "    # Combine ignored layers (including initial layers, classifier, and other blocks)\n",
    "    combined_ignored_layers = []\n",
    "    combined_ignored_layers = ignored_layers + ignored_layers_block\n",
    "    # print(block_to_prune)\n",
    "    if pruning_ratio == 0.99: \n",
    "        print(\"The ignored blocks are:\", combined_ignored_layers)\n",
    "        print(\"The pruned block is:\", block_to_prune)\n",
    "        \n",
    "    print('Pruning ratio here is: ', pruning_ratio)\n",
    "    \n",
    "    # Apply pruning\n",
    "    pruner_group =  tp.pruner.MagnitudePruner( \n",
    "        model,\n",
    "        example_inputs=x,\n",
    "        importance=imp,\n",
    "        pruning_ratio=pruning_ratio,\n",
    "        ignored_layers=combined_ignored_layers,\n",
    "    )\n",
    "\n",
    "    pruner_group.step()\n",
    "\n",
    "    # if i < 2:\n",
    "    #     print(model)\n",
    "\n",
    "    example_inputs = torch.randn(1, 8, 4096).to(device)\n",
    "    macs, nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "    print(f\"MACs: {macs/1e9} G, #Params: {nparams/1e3} K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(trained_model, prune_method, pruning_ratios, train_loader):\n",
    "    # Make a copy of the trained model\n",
    "    model = copy.deepcopy(trained_model)\n",
    "    device = 'cpu'  # Assuming general_device is defined elsewhere\n",
    "    model.to(device)\n",
    "\n",
    "    pruning_info = {\n",
    "    i: {\"block\": model.blocks[i], \"pruning_ratio\": ratio}\n",
    "    for i, ratio in enumerate(pruning_ratios)\n",
    "}\n",
    "\n",
    "    if prune_method == 'channel_pruning_Taylor_importance':\n",
    "        imp = tp.importance.TaylorImportance() \n",
    "\n",
    "        # Prepare a batch from the train loader for pruning and backward pass\n",
    "        batch = next(iter(train_loader))\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Perform forward and backward passes to calculate importance scores if using TaylorImportance\n",
    "        if isinstance(imp, tp.importance.TaylorImportance):\n",
    "            y_hat = model(x)\n",
    "            loss = F.mse_loss(y_hat, y)\n",
    "            loss.backward()\n",
    "\n",
    "        # Define layers to always ignore (conv_stem, bn1, and classifier)\n",
    "        ignored_layers = [\n",
    "            # model.conv_stem, \n",
    "            # model.bn1,\n",
    "            model.global_pool,\n",
    "            model.conv_head,\n",
    "            model.norm_head,\n",
    "            model.act2,\n",
    "            model.flatten,\n",
    "            model.classifier\n",
    "        ]\n",
    "\n",
    "        # Assuming `pruning_info` is a dictionary with blocks and pruning ratios\n",
    "        # Example of how `pruning_info` can be structured:\n",
    "        # pruning_info = {i: {\"block\": model.blocks[i], \"pruning_ratio\": ratio} for i, ratio in enumerate(prune_ratios)}\n",
    "\n",
    "        # Prune each block while ignoring other layers\n",
    "        for i, info in pruning_info.items():\n",
    "            block_to_prune = info[\"block\"]\n",
    "            pruning_ratio = info[\"pruning_ratio\"]\n",
    "            \n",
    "            # Add all blocks to the ignored layers except the block being pruned\n",
    "            ignored_layers_block = [pruning_info[j][\"block\"] for j in range(len(pruning_info)) if j != i]\n",
    "\n",
    "            # Combine fixed ignored layers (conv_stem, bn1, classifier) with the ignored blocks\n",
    "            combined_ignored_layers = ignored_layers + ignored_layers_block\n",
    "\n",
    "            if pruning_ratio == 0.99: \n",
    "                print(\"The ignored blocks are:\", combined_ignored_layers)\n",
    "                print(\"The pruned block is:\", block_to_prune)\n",
    "\n",
    "            # Apply pruning using the combined ignored layers\n",
    "            pruner_group = tp.pruner.MagnitudePruner( \n",
    "                model,\n",
    "                example_inputs=x,\n",
    "                importance=imp,\n",
    "                pruning_ratio=pruning_ratio,\n",
    "                ignored_layers=combined_ignored_layers,\n",
    "                iterative_steps=1,\n",
    "            )\n",
    "\n",
    "            # Step through pruning\n",
    "            pruner_group.step()\n",
    "\n",
    "    # Counting MACs and Params after pruning\n",
    "    example_inputs = torch.randn(1, 8, 4096).to(device)  # Generate example input for calculating MACs and parameters\n",
    "    macs, nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "    print(f\"MACs: {macs / 1e9} G, #Params: {nparams / 1e3} K\")\n",
    "\n",
    "    # Free up GPU memory\n",
    "    del x, y, batch\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform perplexity analysis, return average loss, and calculate relative contribution percentages\n",
    "def perplexity_analysis_with_contributions(original_model, data_loader, criterion, num_iterations=5):\n",
    "    total_block_losses = [0.0 for _ in range(len(original_model.blocks))]\n",
    "\n",
    "    # Step 1: Compute the baseline loss (without block replacement)\n",
    "    print(\"Computing baseline loss without block replacement...\")\n",
    "    baseline_loss = compute_baseline_loss(original_model, data_loader, criterion)\n",
    "    print(f\"Baseline Loss: {baseline_loss}\")\n",
    "    \n",
    "    # Outer loop to run the analysis multiple times for averaging\n",
    "    for iteration in range(num_iterations):\n",
    "        print(f\"Iteration {iteration + 1}/{num_iterations}\")\n",
    "\n",
    "        # Iterate through each block for replacement\n",
    "        for block_idx in range(len(original_model.blocks)):\n",
    "\n",
    "            output_channels = get_first_layer_output_channels(original_model)\n",
    "\n",
    "            print(f\"Replacing block {block_idx}\")\n",
    "            pruning_ratios = (np.eye(len(original_model.blocks)) * math.floor(1000 - (1000/output_channels[block_idx]))/1000)[block_idx]\n",
    "            \n",
    "            pruned_model = prune_model(original_model,'channel_pruning_Taylor_importance', pruning_ratios, data_loader)\n",
    "\n",
    "            # # Replace one block at a time with a linear layer\n",
    "            # modified_model = ModifiedMobileNetV3(original_model, block_to_replace=block_idx)\n",
    "            print(pruned_model)\n",
    "            pruned_model.to(general_device)\n",
    "\n",
    "            # Run validation and compute loss\n",
    "            pruned_model.eval()\n",
    "            total_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in data_loader:\n",
    "                    inputs, targets = inputs.to(general_device), targets.to(general_device)\n",
    "                    outputs = pruned_model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "            # Calculate average loss for the current block\n",
    "            average_loss = total_loss / len(data_loader)\n",
    "            print(f'Loss for block {block_idx} in iteration {iteration + 1}: {average_loss}')\n",
    "            \n",
    "            # Accumulate the loss for each block\n",
    "            total_block_losses[block_idx] += average_loss\n",
    "\n",
    "    # Step 2: Calculate the final averaged loss and contribution for each block across iterations\n",
    "    total_increase_in_loss = 0.0\n",
    "    block_increases = []\n",
    "    \n",
    "    for block_idx in range(len(original_model.blocks)):\n",
    "        final_average_loss = total_block_losses[block_idx] / num_iterations\n",
    "        increase_in_loss = final_average_loss - baseline_loss\n",
    "        block_increases.append(increase_in_loss)\n",
    "        total_increase_in_loss += increase_in_loss  # Accumulate total increase in loss\n",
    "    \n",
    "    # Step 3: Calculate the relative contribution of each block to the total increase in loss\n",
    "    relative_contributions = []\n",
    "    print(\"\\nRelative contribution of each block to total loss increase:\")\n",
    "    for block_idx in range(len(original_model.blocks)):\n",
    "        relative_contribution = (block_increases[block_idx] / total_increase_in_loss) * 100\n",
    "        print(f'Block {block_idx} contributes {relative_contribution:.2f}% to the total increase in loss')\n",
    "        relative_contributions.append(relative_contribution)\n",
    "\n",
    "    return relative_contributions\n",
    "\n",
    "# Helper function to compute the baseline loss (without replacing any block)\n",
    "def compute_baseline_loss(original_model, data_loader, criterion):\n",
    "    original_model.to(general_device)\n",
    "    original_model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(general_device), targets.to(general_device)\n",
    "            outputs = original_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    baseline_loss = total_loss / len(data_loader)\n",
    "    return baseline_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing baseline loss without block replacement...\n",
      "Baseline Loss: 16.092444930308396\n",
      "Iteration 1/1\n",
      "Replacing block 0\n",
      "MACs: 0.022379553 G, #Params: 547.612 K\n",
      "MobileNetV3(\n",
      "  (conv_stem): Conv1d(8, 1, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv1d(1, 1, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(1, 8, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(8, 1, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pw): Conv1d(1, 8, kernel_size=(1,), stride=(1,))\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(8, 40, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv1d(40, 40, kernel_size=(3,), stride=(2,), padding=(1,), groups=40)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv1d(40, 16, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.017)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(16, 56, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv1d(56, 56, kernel_size=(3,), stride=(1,), padding=(1,), groups=56)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv1d(56, 16, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.033)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), groups=64)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(64, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.050)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.067)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.083)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.100)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.117)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(2,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.133)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.150)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.167)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): ConvBnAct(\n",
      "        (conv): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (drop_path): DropPath(drop_prob=0.183)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (global_pool): FastGlobalAvgPool1d()\n",
      "  (conv_head): Conv1d(288, 1024, kernel_size=(1,), stride=(1,))\n",
      "  (norm_head): Identity()\n",
      "  (act2): Hardswish()\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n",
      "Loss for block 0 in iteration 1: 1885.9703289455838\n",
      "Replacing block 1\n",
      "MACs: 0.021290272 G, #Params: 544.94 K\n",
      "MobileNetV3(\n",
      "  (conv_stem): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv1d(16, 16, kernel_size=(3,), stride=(2,), padding=(1,), groups=16)\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pw): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(8, 1, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv1d(1, 1, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv1d(1, 16, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.017)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(16, 1, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv1d(1, 16, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.033)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), groups=64)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(64, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.050)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.067)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.083)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.100)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.117)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(2,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.133)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.150)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.167)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): ConvBnAct(\n",
      "        (conv): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (drop_path): DropPath(drop_prob=0.183)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (global_pool): FastGlobalAvgPool1d()\n",
      "  (conv_head): Conv1d(288, 1024, kernel_size=(1,), stride=(1,))\n",
      "  (norm_head): Identity()\n",
      "  (act2): Hardswish()\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n",
      "Loss for block 1 in iteration 1: 1811.6932831658257\n",
      "Replacing block 2\n",
      "MACs: 0.017996069 G, #Params: 503.43 K\n",
      "MobileNetV3(\n",
      "  (conv_stem): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv1d(16, 16, kernel_size=(3,), stride=(2,), padding=(1,), groups=16)\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pw): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(8, 40, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv1d(40, 40, kernel_size=(3,), stride=(2,), padding=(1,), groups=40)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv1d(40, 16, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.017)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(16, 56, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv1d(56, 56, kernel_size=(3,), stride=(1,), padding=(1,), groups=56)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv1d(56, 16, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.033)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(16, 1, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(1, 1, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(1, 16, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(16, 1, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(1, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.050)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 2, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(2, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 2, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(2, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.067)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 2, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(2, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 2, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(2, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.083)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.100)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.117)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(2,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.133)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.150)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.167)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): ConvBnAct(\n",
      "        (conv): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (drop_path): DropPath(drop_prob=0.183)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (global_pool): FastGlobalAvgPool1d()\n",
      "  (conv_head): Conv1d(288, 1024, kernel_size=(1,), stride=(1,))\n",
      "  (norm_head): Identity()\n",
      "  (act2): Hardswish()\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n",
      "Loss for block 2 in iteration 1: 1073.878168106079\n",
      "Replacing block 3\n",
      "MACs: 0.021287922 G, #Params: 533.146 K\n",
      "MobileNetV3(\n",
      "  (conv_stem): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv1d(16, 16, kernel_size=(3,), stride=(2,), padding=(1,), groups=16)\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pw): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(8, 40, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv1d(40, 40, kernel_size=(3,), stride=(2,), padding=(1,), groups=40)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv1d(40, 16, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.017)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(16, 56, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv1d(56, 56, kernel_size=(3,), stride=(1,), padding=(1,), groups=56)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv1d(56, 16, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.033)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), groups=64)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(64, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.050)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.067)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.083)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 1, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(1, 24, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(24, 1, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(1, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.100)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 1, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(1, 24, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(24, 1, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(1, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.117)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(2,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.133)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.150)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.167)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): ConvBnAct(\n",
      "        (conv): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (drop_path): DropPath(drop_prob=0.183)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (global_pool): FastGlobalAvgPool1d()\n",
      "  (conv_head): Conv1d(288, 1024, kernel_size=(1,), stride=(1,))\n",
      "  (norm_head): Identity()\n",
      "  (act2): Hardswish()\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n",
      "Loss for block 3 in iteration 1: 16.50685574275752\n",
      "Replacing block 4\n",
      "MACs: 0.013497573 G, #Params: 380.886 K\n",
      "MobileNetV3(\n",
      "  (conv_stem): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv1d(16, 16, kernel_size=(3,), stride=(2,), padding=(1,), groups=16)\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pw): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(8, 40, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv1d(40, 40, kernel_size=(3,), stride=(2,), padding=(1,), groups=40)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv1d(40, 16, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.017)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(16, 56, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv1d(56, 56, kernel_size=(3,), stride=(1,), padding=(1,), groups=56)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv1d(56, 16, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.033)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), groups=64)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(64, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.050)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.067)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.083)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.100)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.117)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 1, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(1, 1, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(1, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 1, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(1, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.133)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(48, 2, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(2, 72, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(72, 2, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(2, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.150)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv1d(48, 2, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(2, 72, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(72, 2, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(2, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.167)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): ConvBnAct(\n",
      "        (conv): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (drop_path): DropPath(drop_prob=0.183)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (global_pool): FastGlobalAvgPool1d()\n",
      "  (conv_head): Conv1d(288, 1024, kernel_size=(1,), stride=(1,))\n",
      "  (norm_head): Identity()\n",
      "  (act2): Hardswish()\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n",
      "Loss for block 4 in iteration 1: 743.862470457289\n",
      "Replacing block 5\n",
      "MACs: 0.021272224 G, #Params: 239.957 K\n",
      "MobileNetV3(\n",
      "  (conv_stem): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "  (bn1): GBN(\n",
      "    (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop): Identity()\n",
      "    (act): Hardswish()\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv1d(16, 16, kernel_size=(3,), stride=(2,), padding=(1,), groups=16)\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pw): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(8, 40, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv1d(40, 40, kernel_size=(3,), stride=(2,), padding=(1,), groups=40)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv1d(40, 16, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.017)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(16, 56, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv1d(56, 56, kernel_size=(3,), stride=(1,), padding=(1,), groups=56)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv1d(56, 16, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.033)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(64, 64, kernel_size=(5,), stride=(2,), padding=(2,), groups=64)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(64, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.050)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.067)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(1,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.083)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.100)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(72, 72, kernel_size=(5,), stride=(1,), padding=(2,), groups=72)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(24, 72, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(72, 24, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.117)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv1d(24, 144, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(144, 144, kernel_size=(5,), stride=(2,), padding=(2,), groups=144)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(144, 40, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(40, 144, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(144, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.133)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.150)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv1d(48, 288, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (conv_dw): Conv1d(288, 288, kernel_size=(5,), stride=(1,), padding=(2,), groups=288)\n",
      "        (bn2): GBN(\n",
      "          (bn): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv1d(288, 72, kernel_size=(1,), stride=(1,))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv1d(72, 288, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (conv_pwl): Conv1d(288, 48, kernel_size=(1,), stride=(1,))\n",
      "        (bn3): GBN(\n",
      "          (bn): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.167)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): ConvBnAct(\n",
      "        (conv): Conv1d(48, 1, kernel_size=(1,), stride=(1,))\n",
      "        (bn1): GBN(\n",
      "          (bn): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Identity()\n",
      "          (act): Hardswish()\n",
      "        )\n",
      "        (aa): Identity()\n",
      "        (drop_path): DropPath(drop_prob=0.183)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (global_pool): FastGlobalAvgPool1d()\n",
      "  (conv_head): Conv1d(1, 1024, kernel_size=(1,), stride=(1,))\n",
      "  (norm_head): Identity()\n",
      "  (act2): Hardswish()\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n",
      "Loss for block 5 in iteration 1: 699.0984265645345\n",
      "\n",
      "Relative contribution of each block to total loss increase:\n",
      "Block 0 contributes 30.48% to the total increase in loss\n",
      "Block 1 contributes 29.27% to the total increase in loss\n",
      "Block 2 contributes 17.24% to the total increase in loss\n",
      "Block 3 contributes 0.01% to the total increase in loss\n",
      "Block 4 contributes 11.86% to the total increase in loss\n",
      "Block 5 contributes 11.13% to the total increase in loss\n"
     ]
    }
   ],
   "source": [
    "relative_contribution = perplexity_analysis_with_contributions(original_model, test_loader, criterion = nn.MSELoss(), num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "\n",
    "# model = original_model\n",
    "\n",
    "# # Function to compute the off-diagonal mean of cosine distances\n",
    "# def offdiagonal_mean(cos_dist):\n",
    "#     n = cos_dist.shape[1]\n",
    "#     # Create a mask for off-diagonal elements\n",
    "#     mask = ~torch.eye(n, dtype=bool, device=cos_dist.device)  # [channels, channels], mask for off-diagonal\n",
    "    \n",
    "#     # Apply the mask to extract off-diagonal elements from the last two dimensions\n",
    "#     off_diag_elements = cos_dist[:, mask].view(cos_dist.size(0), -1)\n",
    "    \n",
    "#     # Return the mean of the off-diagonal elements\n",
    "#     return off_diag_elements.mean().item()\n",
    "\n",
    "# # Function to compute cosine distances between channels (row-wise)\n",
    "# def compute_cosine_distance(x):\n",
    "#     # Flatten along the temporal dimension, keeping channel dimension separate\n",
    "#     x = x.flatten(start_dim=2)  # [batch_size, channels, sequence_length]\n",
    "    \n",
    "#     # Initialize cosine distance matrix\n",
    "#     cos_dist = torch.zeros(x.size(0), x.size(1), x.size(1), device=x.device)  # [batch_size, channels, channels]\n",
    "\n",
    "#     # Compute cosine similarity for each pair of channels using F.cosine_similarity\n",
    "#     for i in range(x.size(1)):  # Loop over channels\n",
    "#         for j in range(i, x.size(1)):  # Compare channels i and j\n",
    "#             cos_sim = F.cosine_similarity(x[:, i, :], x[:, j, :], dim=1)\n",
    "#             cos_dist[:, i, j] = 1 - cos_sim  # Convert similarity to distance\n",
    "#             if i != j:\n",
    "#                 cos_dist[:, j, i] = cos_dist[:, i, j]  # Symmetric\n",
    "\n",
    "#     return cos_dist\n",
    "\n",
    "# # Forward hook to capture input and output activations of blocks\n",
    "# class CosineDistanceHook:\n",
    "#     def __init__(self):\n",
    "#         self.input_distances = []\n",
    "#         self.output_distances = []\n",
    "#         self.input_cos_dists = []  # Store actual cosine distance matrices for input\n",
    "#         self.output_cos_dists = [] # Store actual cosine distance matrices for output\n",
    "    \n",
    "#     def hook_fn(self, module, input, output):\n",
    "#         # Compute cosine distance for input channels (row-wise)\n",
    "#         input_tensor = input[0]  # Input is a tuple\n",
    "#         input_cos_dist = compute_cosine_distance(input_tensor)\n",
    "#         mean_input = offdiagonal_mean(input_cos_dist)\n",
    "\n",
    "#         # Compute cosine distance for output channels (row-wise)\n",
    "#         output_cos_dist = compute_cosine_distance(output)\n",
    "#         mean_output = offdiagonal_mean(output_cos_dist)\n",
    "\n",
    "#         # Store results\n",
    "#         self.input_distances.append(mean_input)\n",
    "#         self.output_distances.append(mean_output)\n",
    "\n",
    "#         # Store the actual cosine distance matrices for inspection\n",
    "#         self.input_cos_dists.append(input_cos_dist)  \n",
    "#         self.output_cos_dists.append(output_cos_dist)\n",
    "\n",
    "# # Initialize the hook\n",
    "# hook = CosineDistanceHook()\n",
    "\n",
    "# # Register the hook for each block in your model\n",
    "# hooks = []\n",
    "# for block in model.blocks:\n",
    "#     hooks.append(block.register_forward_hook(hook.hook_fn))\n",
    "\n",
    "# # Perform a forward pass with dummy input\n",
    "# x, _ = next(iter(train_loader))\n",
    "# # x = x[0].unsqueeze(0)\n",
    "# x = x.to(general_device)\n",
    "\n",
    "# model(x)\n",
    "\n",
    "# # Calculate differences between input and output distances for each block\n",
    "# differences = [out - inp for inp, out in zip(hook.input_distances, hook.output_distances)]\n",
    "\n",
    "# # Cleanup hooks\n",
    "# for h in hooks:\n",
    "#     h.remove()\n",
    "\n",
    "# # Display the cosine distance differences\n",
    "# print(\"Cosine distance differences between input and output for each block:\")\n",
    "# for i, diff in enumerate(differences):\n",
    "#     print(f\"Block {i}: {diff:.4f}\")\n",
    "\n",
    "# # Optional: Inspect the cosine distance matrices and their mean values\n",
    "# print(\"\\nCosine distance matrices and means for input and output of each block:\")\n",
    "\n",
    "# for i, (input_cos_dist, output_cos_dist, mean_input, mean_output) in enumerate(zip(hook.input_cos_dists, hook.output_cos_dists, hook.input_distances, hook.output_distances)):\n",
    "#     print(f\"\\nBlock {i}:\")\n",
    "#     print(f\"Mean Input Cosine Distance (off-diagonal): {mean_input:.4f}\")\n",
    "#     print(f\"Mean Output Cosine Distance (off-diagonal): {mean_output:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = original_model\n",
    "\n",
    "# # Function to compute the off-diagonal mean of cosine distances\n",
    "# def offdiagonal_mean(cos_dist):\n",
    "#     n = cos_dist.shape[1]\n",
    "#     # Create a mask for off-diagonal elements\n",
    "#     mask = ~torch.eye(n, dtype=bool, device=cos_dist.device)  # [channels, channels], mask for off-diagonal\n",
    "    \n",
    "#     # Apply the mask to extract off-diagonal elements from the last two dimensions\n",
    "#     off_diag_elements = cos_dist[:, mask].view(cos_dist.size(0), -1)\n",
    "    \n",
    "#     # Return the mean of the off-diagonal elements\n",
    "#     return off_diag_elements.mean().item()\n",
    "\n",
    "# # Function to compute cosine distances between channels\n",
    "# def compute_cosine_distance(x):\n",
    "#     # Flatten along the temporal dimension, keeping channel dimension separate\n",
    "#     x = x.flatten(start_dim=2)  # [batch_size, channels, sequence_length]\n",
    "    \n",
    "#     # Initialize cosine distance matrix\n",
    "#     cos_dist = torch.zeros(x.size(0), x.size(1), x.size(1), device=x.device)  # [batch_size, channels, channels]\n",
    "\n",
    "#     # Compute cosine similarity for each pair of channels using F.cosine_similarity\n",
    "#     for i in range(x.size(1)):\n",
    "#         for j in range(x.size(1)):\n",
    "#             cos_sim = F.cosine_similarity(x[:, i, :], x[:, j, :], dim=1)\n",
    "#             cos_dist[:, i, j] = 1 - cos_sim  # Convert to cosine distance\n",
    "\n",
    "#     return cos_dist\n",
    "\n",
    "# # Forward hook to capture input and output activations of blocks\n",
    "# class CosineDistanceHook:\n",
    "#     def __init__(self):\n",
    "#         self.input_distances = []\n",
    "#         self.output_distances = []\n",
    "#         self.input_cos_dists = []  # Store actual cosine distance matrices for input\n",
    "#         self.output_cos_dists = [] # Store actual cosine distance matrices for output\n",
    "    \n",
    "#     def hook_fn(self, module, input, output):\n",
    "#         # Compute cosine distance for input channels\n",
    "#         input_tensor = input[0]  # Input is a tuple\n",
    "#         input_cos_dist = compute_cosine_distance(input_tensor)\n",
    "#         mean_input = offdiagonal_mean(input_cos_dist)\n",
    "\n",
    "#         # Compute cosine distance for output channels\n",
    "#         output_cos_dist = compute_cosine_distance(output)\n",
    "#         mean_output = offdiagonal_mean(output_cos_dist)\n",
    "\n",
    "#         # Store results\n",
    "#         self.input_distances.append(mean_input)\n",
    "#         self.output_distances.append(mean_output)\n",
    "\n",
    "#         # Store the actual cosine distance matrices for inspection\n",
    "#         self.input_cos_dists.append(input_cos_dist)  \n",
    "#         self.output_cos_dists.append(output_cos_dist)\n",
    "\n",
    "# # Initialize the hook\n",
    "# hook = CosineDistanceHook()\n",
    "\n",
    "# # Register the hook for each block in your model\n",
    "# hooks = []\n",
    "# for block in model.blocks:\n",
    "#     hooks.append(block.register_forward_hook(hook.hook_fn))\n",
    "\n",
    "# # Perform a forward pass with dummy input\n",
    "# x, _ = next(iter(train_loader))\n",
    "# x = x[0].unsqueeze(0)\n",
    "# x = x.to(general_device)\n",
    "\n",
    "# model(x)\n",
    "\n",
    "# # Calculate differences between input and output distances for each block\n",
    "# differences = [out - inp for inp, out in zip(hook.input_distances, hook.output_distances)]\n",
    "\n",
    "# # Cleanup hooks\n",
    "# for h in hooks:\n",
    "#     h.remove()\n",
    "\n",
    "# # Display the cosine distance differences\n",
    "# print(\"Cosine distance differences between input and output for each block:\")\n",
    "# for i, diff in enumerate(differences):\n",
    "#     print(f\"Block {i}: {diff:.4f}\")\n",
    "\n",
    "# # Optional: Inspect the cosine distance matrices and their mean values\n",
    "# print(\"\\nCosine distance matrices and means for input and output of each block:\")\n",
    "\n",
    "# for i, (input_cos_dist, output_cos_dist, mean_input, mean_output) in enumerate(zip(hook.input_cos_dists, hook.output_cos_dists, hook.input_distances, hook.output_distances)):\n",
    "#     print(f\"\\nBlock {i}:\")\n",
    "#     # print(f\"Input Cosine Distance Matrix:\\n{input_cos_dist}\")\n",
    "#     print(f\"Mean Input Cosine Distance (off-diagonal): {mean_input:.4f}\")\n",
    "#     # print(f\"Output Cosine Distance Matrix:\\n{output_cos_dist}\")\n",
    "#     print(f\"Mean Output Cosine Distance (off-diagonal): {mean_output:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Covariance Matrix\n",
    "\n",
    "# # Assuming your model is already defined as `model`\n",
    "# # model = original_model  # Replace with your actual model instance\n",
    "\n",
    "# # Define a hook to capture block outputs\n",
    "# activations = {}\n",
    "\n",
    "# def get_activation(name):\n",
    "#     def hook(model, input, output):\n",
    "#         activations[name] = output\n",
    "#     return hook\n",
    "\n",
    "# # Register hooks for each block in your model\n",
    "# block_names = ['blocks.0', 'blocks.1', 'blocks.2', 'blocks.3', 'blocks.4', 'blocks.5']\n",
    "\n",
    "# for name in block_names:\n",
    "#     layer = dict(model.named_modules())[name]\n",
    "#     layer.register_forward_hook(get_activation(name))\n",
    "\n",
    "# # Get a batch of data from the data loader\n",
    "# x, _ = next(iter(train_loader))  # x.shape will be [batch_size, channels, spatial_dim]\n",
    "# x = x.to(general_device)  # Move to the general device (CPU or GPU)\n",
    "\n",
    "# # Perform a forward pass to capture activations\n",
    "# output = model(x)\n",
    "\n",
    "# # Initialize variables to store results for all blocks\n",
    "# block_metrics = {name: {'covariance_matrices': [], 'mean_covariances': [], \n",
    "#                         'variance_covariances': [], 'ranks': [], 'eigenvalues': [],\n",
    "#                         'condition_numbers': [], 'spectral_norms': [], 'dominance_ratios': []}\n",
    "#                  for name in block_names}\n",
    "\n",
    "# # Iterate over each sample in the batch\n",
    "# batch_size = x.shape[0]\n",
    "\n",
    "# for i in range(50):\n",
    "#     # For each block, compute covariance metrics for the current sample\n",
    "#     for block_name, activation in activations.items():\n",
    "#         # Get the ith sample from the block output\n",
    "#         sample = activation[i]  # Shape: [channels, spatial_dim]\n",
    "\n",
    "#         # Compute covariance matrix for the channels of this sample\n",
    "#         # First, reshape the sample to [channels, spatial_dim]\n",
    "#         sample = sample.view(sample.shape[0], -1)  # Flatten spatial dimensions if needed\n",
    "        \n",
    "#         # Center the data by subtracting the mean across the spatial dimensions\n",
    "#         centered_sample = sample - sample.mean(dim=1, keepdim=True)\n",
    "        \n",
    "#         # Compute the covariance matrix: cov(X) = (X * X.T) / (n - 1)\n",
    "#         covariance_matrix = torch.mm(centered_sample, centered_sample.T) / (sample.shape[1] - 1)\n",
    "#         block_metrics[block_name]['covariance_matrices'].append(covariance_matrix)\n",
    "\n",
    "#         # 1. Mean of the covariance (off-diagonal elements)\n",
    "#         n = covariance_matrix.shape[0]\n",
    "#         off_diagonal_mask = ~torch.eye(n, dtype=bool)\n",
    "#         mean_covariance = covariance_matrix[off_diagonal_mask].mean()\n",
    "\n",
    "#         # 2. Variance of the covariance (off-diagonal elements)\n",
    "#         variance_covariance = covariance_matrix[off_diagonal_mask].var()\n",
    "\n",
    "#         # 3. Rank of the covariance matrix\n",
    "#         rank = torch.linalg.matrix_rank(covariance_matrix)\n",
    "\n",
    "#         # 4. Singular values (for computing spectral norm and dominance ratio)\n",
    "#         U, S, V = torch.linalg.svd(covariance_matrix, full_matrices=False)\n",
    "#         spectral_norm = S[0]  # The largest singular value (spectral norm)\n",
    "#         other_singular_values = S[1:]  # Other singular values\n",
    "\n",
    "#         # 5. Condition number of the covariance matrix\n",
    "#         condition_number = torch.linalg.cond(covariance_matrix)\n",
    "\n",
    "#         # 6. Compute Dominance Ratio: spectral_norm / mean(other_singular_values)\n",
    "#         if len(other_singular_values) > 0:\n",
    "#             mean_other_singular_values = other_singular_values.mean()\n",
    "#             dominance_ratio = spectral_norm / mean_other_singular_values\n",
    "#         else:\n",
    "#             dominance_ratio = torch.tensor(float('nan'))  # Handle cases where there are no other singular values\n",
    "\n",
    "#         # Store the metrics for the current block and sample\n",
    "#         block_metrics[block_name]['mean_covariances'].append(mean_covariance)\n",
    "#         block_metrics[block_name]['variance_covariances'].append(variance_covariance)\n",
    "#         block_metrics[block_name]['ranks'].append(rank)\n",
    "#         block_metrics[block_name]['condition_numbers'].append(condition_number)\n",
    "#         block_metrics[block_name]['spectral_norms'].append(spectral_norm)\n",
    "#         block_metrics[block_name]['dominance_ratios'].append(dominance_ratio)\n",
    "\n",
    "# # Aggregate results for each block over the entire batch\n",
    "# for block_name in block_names:\n",
    "#     print(f\"\\nResults for block: {block_name}\")\n",
    "    \n",
    "#     # Aggregating results\n",
    "#     overall_mean_covariance = torch.stack(block_metrics[block_name]['mean_covariances']).mean()\n",
    "#     overall_variance_covariance = torch.stack(block_metrics[block_name]['variance_covariances']).mean()\n",
    "#     overall_rank = torch.stack(block_metrics[block_name]['ranks']).float().mean()\n",
    "#     overall_condition_number = torch.stack(block_metrics[block_name]['condition_numbers']).float().mean()\n",
    "#     overall_spectral_norm = torch.stack(block_metrics[block_name]['spectral_norms']).float().mean()\n",
    "#     overall_dominance_ratio = torch.stack(block_metrics[block_name]['dominance_ratios']).float().mean()\n",
    "\n",
    "#     # Printing the aggregated results for this block\n",
    "#     print(f\"Overall mean covariance: {overall_mean_covariance.item()}\")\n",
    "#     print(f\"Overall variance of covariance: {overall_variance_covariance.item()}\")\n",
    "#     print(f\"Overall rank: {overall_rank.item()}\")\n",
    "#     print(f\"Overall condition number: {overall_condition_number.item()}\")\n",
    "#     print(f\"Overall spectral norm: {overall_spectral_norm.item()}\")\n",
    "#     print(f\"Overall dominance ratio: {overall_dominance_ratio.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Cosine Similarity Matrix\n",
    "\n",
    "# # Assuming your model is already defined as `model`\n",
    "# model = original_model  # Replace with your actual model instance\n",
    "\n",
    "# # Define a hook to capture block outputs\n",
    "# activations = {}\n",
    "\n",
    "# def get_activation(name):\n",
    "#     def hook(model, input, output):\n",
    "#         activations[name] = output\n",
    "#     return hook\n",
    "\n",
    "# # Register hooks for each block in your model (you can customize based on your block structure)\n",
    "# block_names = ['blocks.0', 'blocks.1', 'blocks.2', 'blocks.3', 'blocks.4', 'blocks.5']\n",
    "\n",
    "# for name in block_names:\n",
    "#     layer = dict(model.named_modules())[name]\n",
    "#     layer.register_forward_hook(get_activation(name))\n",
    "\n",
    "# # Get a batch of data from the data loader\n",
    "# x, _ = next(iter(train_loader))  # x.shape will be [batch_size, channels, spatial_dim]\n",
    "# x = x.to(general_device)  # Move to the general device (CPU or GPU)\n",
    "\n",
    "# # Perform a forward pass to capture activations\n",
    "# output = model(x)\n",
    "\n",
    "# # Initialize variables to store results for all blocks\n",
    "# block_metrics = {name: {'mean_similarities': [], 'median_similarities': [], \n",
    "#                         'variance_similarities': [], 'ranks': [], 'determinants': [],\n",
    "#                         'condition_numbers': [], 'spectral_norms': [], 'dominance_ratios': [], 'normalized_dominance_ratios': []}\n",
    "#                  for name in block_names}\n",
    "\n",
    "# # Iterate over each sample in the batch\n",
    "# batch_size = x.shape[0]\n",
    "\n",
    "# for i in range(64):\n",
    "#     # For each block, compute similarity metrics for the current sample\n",
    "#     for block_name, activation in activations.items():\n",
    "#         # Get the ith sample from the block output\n",
    "#         sample = activation[i]  # Shape: [channels, spatial_dim]\n",
    "#         sample = sample.unsqueeze(0)  # Add a batch dimension back for consistency\n",
    "\n",
    "#         # Compute cosine similarity matrix for the channels of this sample\n",
    "#         cosine_similarity_matrix = F.cosine_similarity(sample[:, None, :, :], sample[:, :, None, :], dim=-1).squeeze(0)\n",
    "#         # cosine_similarity_matrix = 1 - (cosine_similarity_matrix)\n",
    "#         # Matrix-based measurements for this block and sample\n",
    "#         n = cosine_similarity_matrix.shape[0]\n",
    "#         off_diagonal_mask = ~torch.eye(n, dtype=bool)\n",
    "\n",
    "#         # # 1. Mean and median similarity\n",
    "#         # mean_similarity = cosine_similarity_matrix[off_diagonal_mask].mean()\n",
    "#         # median_similarity = torch.quantile(cosine_similarity_matrix[off_diagonal_mask], 0.7) #cosine_similarity_matrix[off_diagonal_mask].median()\n",
    "\n",
    "#         # # # 2. Variance of off-diagonal elements\n",
    "#         # variance_similarity = cosine_similarity_matrix[off_diagonal_mask].var()\n",
    "\n",
    "#         # # 3. Rank of the cosine similarity matrix\n",
    "#         # rank = torch.linalg.matrix_rank(cosine_similarity_matrix)\n",
    "\n",
    "#         # # 4. Determinant of the cosine similarity matrix\n",
    "#         # try:\n",
    "#         #     determinant = torch.det(cosine_similarity_matrix)\n",
    "#         # except RuntimeError:\n",
    "#         #     determinant = torch.tensor(float('nan'))  # Handle non-invertible cases\n",
    "\n",
    "#         # # 5. Condition number\n",
    "#         # condition_number = torch.linalg.cond(cosine_similarity_matrix)\n",
    "\n",
    "#         # 6. Spectral norm (largest singular value) and dominance ratio\n",
    "#         U, S, V = torch.linalg.svd(cosine_similarity_matrix, full_matrices=False)\n",
    "#         spectral_norm = S[0]  # The largest singular value (spectral norm)\n",
    "#         other_singular_values = S[1:]  # Other singular values\n",
    "\n",
    "#         # Dominance Ratio: spectral_norm / mean(other_singular_values)\n",
    "#         if len(other_singular_values) > 0:\n",
    "#             mean_other_singular_values = other_singular_values.mean()\n",
    "#             dominance_ratio = spectral_norm / mean_other_singular_values\n",
    "#             normalized_dominance_ratio = dominance_ratio / len(other_singular_values)\n",
    "#         else:\n",
    "#             dominance_ratio = torch.tensor(float('nan'))  # Handle cases where there are no other singular values\n",
    "#             normalized_dominance_ratio = torch.tensor(float('nan'))  # Handle cases where there are no other singular values\n",
    "\n",
    "\n",
    "#         # Store the metrics for the current block and sample\n",
    "#         # block_metrics[block_name]['mean_similarities'].append(mean_similarity)\n",
    "#         # block_metrics[block_name]['median_similarities'].append(median_similarity)\n",
    "#         # block_metrics[block_name]['variance_similarities'].append(variance_similarity)\n",
    "#         # block_metrics[block_name]['ranks'].append(rank)\n",
    "#         # block_metrics[block_name]['determinants'].append(determinant)\n",
    "#         # block_metrics[block_name]['condition_numbers'].append(condition_number)\n",
    "#         block_metrics[block_name]['spectral_norms'].append(spectral_norm)\n",
    "#         block_metrics[block_name]['dominance_ratios'].append(dominance_ratio)\n",
    "#         block_metrics[block_name]['normalized_dominance_ratios'].append(normalized_dominance_ratio)\n",
    "\n",
    "# # Aggregate results for each block over the entire batch\n",
    "# for block_name in block_names:\n",
    "#     print(f\"\\nResults for block: {block_name}\")\n",
    "    \n",
    "#     # Aggregating results\n",
    "#     # overall_mean_similarity = torch.stack(block_metrics[block_name]['mean_similarities']).mean()\n",
    "#     # overall_median_similarity = torch.stack(block_metrics[block_name]['median_similarities']).median()\n",
    "#     # overall_variance_similarity = torch.stack(block_metrics[block_name]['variance_similarities']).mean()\n",
    "#     # overall_rank = torch.stack(block_metrics[block_name]['ranks']).float().mean()\n",
    "#     # overall_condition_number = torch.stack(block_metrics[block_name]['condition_numbers']).float().mean()\n",
    "#     overall_spectral_norm = torch.stack(block_metrics[block_name]['spectral_norms']).float().mean()\n",
    "#     overall_dominance_ratio = torch.stack(block_metrics[block_name]['dominance_ratios']).float().mean()\n",
    "#     overall_normalized_dominance_ratios = torch.stack(block_metrics[block_name]['normalized_dominance_ratios']).float().mean()\n",
    "\n",
    "#     # Printing the aggregated results for this block\n",
    "#     # print(f\"Overall mean similarity: {overall_mean_similarity.item()}\")\n",
    "#     # print(f\"Overall median similarity: {overall_median_similarity.item()}\")\n",
    "#     # print(f\"Overall variance similarity: {overall_variance_similarity.item()}\")\n",
    "#     # print(f\"Overall rank: {overall_rank.item()}\")\n",
    "#     # print(f\"Overall condition number: {overall_condition_number.item()}\")\n",
    "#     print(f\"Overall spectral norm: {overall_spectral_norm.item()}\")\n",
    "#     print(f\"Overall dominance ratio: {overall_dominance_ratio.item()}\")\n",
    "#     print(f\"Overall normalized dominance ratio: {overall_normalized_dominance_ratios.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Method 1\n",
    "\n",
    "# class LinearChannelInterpolation(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(LinearChannelInterpolation, self).__init__()\n",
    "#         self.in_channels = in_channels\n",
    "#         self.out_channels = out_channels\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         device = x.device  # Get the device of the input tensor\n",
    "\n",
    "#         if self.in_channels < self.out_channels:\n",
    "#             # Interpolate linearly between channels\n",
    "#             expanded_channels = torch.linspace(0, self.in_channels - 1, steps=self.out_channels, device=device)  \n",
    "#             indices = expanded_channels.long()  # Convert to long for indexing\n",
    "            \n",
    "#             # Ensure indices do not go out of bounds\n",
    "#             indices_plus_1 = torch.clamp(indices + 1, max=self.in_channels - 1)\n",
    "\n",
    "#             alpha = expanded_channels - indices.float()  # Calculate interpolation weights\n",
    "\n",
    "#             # Ensure all tensors are on the same device\n",
    "#             x_interpolated = (1 - alpha).unsqueeze(0).unsqueeze(2).to(device) * x[:, indices, :] + \\\n",
    "#                              alpha.unsqueeze(0).unsqueeze(2).to(device) * x[:, indices_plus_1, :]\n",
    "#             return x_interpolated\n",
    "#         else:\n",
    "#             # If no interpolation needed, return the input as is\n",
    "#             return x\n",
    "        \n",
    "# class GroupwiseChannelPooling(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, pool_type='avg'):\n",
    "#         super(GroupwiseChannelPooling, self).__init__()\n",
    "#         self.in_channels = in_channels\n",
    "#         self.out_channels = out_channels\n",
    "#         self.pool_type = pool_type\n",
    "        \n",
    "#         # Ensure out_channels divides in_channels evenly for simplicity\n",
    "#         assert self.in_channels % self.out_channels == 0, \"in_channels must be divisible by out_channels\"\n",
    "#         self.group_size = self.in_channels // self.out_channels\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Step 1: Group channels\n",
    "#         batch_size, _, seq_length = x.shape\n",
    "        \n",
    "#         # Reshape the input tensor to group the channels for pooling\n",
    "#         x_grouped = x.view(batch_size, self.out_channels, self.group_size, seq_length)\n",
    "\n",
    "#         # Step 2: Apply pooling within each group\n",
    "#         if self.pool_type == 'max':\n",
    "#             x_pooled, _ = torch.max(x_grouped, dim=2)  # Max pooling over the group dimension\n",
    "#         elif self.pool_type == 'avg':\n",
    "#             x_pooled = torch.mean(x_grouped, dim=2)    # Average pooling over the group dimension\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unsupported pool type: {self.pool_type}\")\n",
    "        \n",
    "#         return x_pooled\n",
    "    \n",
    "\n",
    "# class DynamicPoolingOrInterpolation(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, pool_type='avg'):\n",
    "#         super(DynamicPoolingOrInterpolation, self).__init__()\n",
    "#         self.in_channels = in_channels\n",
    "#         self.out_channels = out_channels\n",
    "#         self.pool_type = pool_type\n",
    "\n",
    "#         # Initialize group-wise pooling and interpolation layers\n",
    "#         if self.in_channels > self.out_channels:\n",
    "#             # Prepare pooling layer for reduction\n",
    "#             self.pooling_layer = GroupwiseChannelPooling(in_channels, out_channels, pool_type=pool_type)\n",
    "#         elif self.in_channels < self.out_channels:\n",
    "#             # Prepare interpolation layer\n",
    "#             self.interpolation_layer = LinearChannelInterpolation(in_channels, out_channels)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Step 1: Check if reduction or interpolation is needed\n",
    "#         if self.in_channels > self.out_channels:\n",
    "#             # Perform reduction (Pooling)\n",
    "#             # print(\"Performing reduction\")\n",
    "#             x_pooled = self.pooling_layer(x)  # Apply pooling\n",
    "#             return x_pooled\n",
    "#         elif self.in_channels < self.out_channels:\n",
    "#             # print(\"Performing interpolation\")\n",
    "#             x_interpolated = self.interpolation_layer(x)  # Apply interpolation\n",
    "#             return x_interpolated\n",
    "#         else:\n",
    "#             # No change needed if the number of input channels equals the number of output channels\n",
    "#             return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Method 2\n",
    "\n",
    "# class MinimalChangeConv1d(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, seed=42):\n",
    "#         super(MinimalChangeConv1d, self).__init__()\n",
    "#         self.in_channels = in_channels\n",
    "#         self.out_channels = out_channels\n",
    "#         self.seed = seed  # Store the seed\n",
    "#         # Define the Conv1d layer with kernel size 1\n",
    "#         self.conv = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "#         # Initialize weights and biases for minimal changes\n",
    "#         self.init_weights()\n",
    "\n",
    "#     def init_weights(self):\n",
    "#         # Set a fixed seed for reproducibility of weights\n",
    "#         torch.manual_seed(self.seed)\n",
    "#         if torch.cuda.is_available():\n",
    "#             torch.cuda.manual_seed_all(self.seed)\n",
    "\n",
    "#         # Initialize weights close to identity for minimal change\n",
    "#         nn.init.xavier_uniform_(self.conv.weight, gain=0.01)  # Small weights for minimal change\n",
    "#         if self.conv.bias is not None:\n",
    "#             nn.init.constant_(self.conv.bias, 0)  # Bias initialized to zero\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ModifiedMobileNetV3(nn.Module):\n",
    "#     def __init__(self, original_model, block_to_replace=None, shared_conv1d_layer=None):\n",
    "#         super(ModifiedMobileNetV3, self).__init__()\n",
    "        \n",
    "#         self.conv_stem = original_model.conv_stem\n",
    "#         self.bn1 = original_model.bn1\n",
    "\n",
    "#         # Use the same Conv1d layer for all replacements, defined in advance\n",
    "#         self.shared_conv1d_layer = shared_conv1d_layer\n",
    "\n",
    "#         # Replacing the specified block with the shared Conv1d (kernel_size=1)\n",
    "#         self.blocks = nn.Sequential(*[\n",
    "#             self._replace_with_conv1d(block, idx, block_to_replace)\n",
    "#             for idx, block in enumerate(original_model.blocks)\n",
    "#         ])\n",
    "        \n",
    "#         self.global_pool = original_model.global_pool\n",
    "        \n",
    "#         # Using the same classifier and rest of the layers after the blocks\n",
    "#         self.conv_head = original_model.conv_head\n",
    "#         self.norm_head = original_model.norm_head\n",
    "#         self.act2 = original_model.act2\n",
    "#         self.flatten = original_model.flatten\n",
    "#         self.classifier = original_model.classifier\n",
    "\n",
    "#     def _replace_with_conv1d(self, block, idx, block_to_replace):\n",
    "#         if idx == block_to_replace:\n",
    "#             input_channels, output_channels = self._get_block_channels(block)\n",
    "\n",
    "#             # Check if shared Conv1d layer is defined; if not, create it\n",
    "#             if self.shared_conv1d_layer is None:\n",
    "#                 self.shared_conv1d_layer = MinimalChangeConv1d(input_channels, output_channels, seed=2525) #DynamicPoolingOrInterpolation(input_channels, output_channels, pool_type='avg') #nn.Conv1d(input_channels, output_channels, kernel_size=1)\n",
    "\n",
    "#             # Replace with the shared Conv1d layer (always return the same layer)\n",
    "#             return self.shared_conv1d_layer\n",
    "#         else:\n",
    "#             return block\n",
    "\n",
    "#     def _get_block_channels(self, block):\n",
    "#         input_channels = None\n",
    "#         output_channels = None\n",
    "\n",
    "#         # Iterate over the layers in the block to find Conv1d layers\n",
    "#         for layer in block.modules():\n",
    "#             if isinstance(layer, nn.Conv1d):\n",
    "#                 if input_channels is None:\n",
    "#                     # Use the first Conv1d's in_channels as input channels\n",
    "#                     input_channels = layer.in_channels\n",
    "#                 # Use the last Conv1d's out_channels as output channels\n",
    "#                 output_channels = layer.out_channels\n",
    "        \n",
    "#         if input_channels is None or output_channels is None:\n",
    "#             raise RuntimeError(\"No Conv1d layers found in the block to extract input/output channels.\")\n",
    "        \n",
    "#         return input_channels, output_channels\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv_stem(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.blocks(x)\n",
    "#         x = self.global_pool(x)\n",
    "#         x = self.conv_head(x)\n",
    "#         x = self.norm_head(x)\n",
    "#         x = self.act2(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Function to perform perplexity analysis, return average loss, and calculate contribution percentages\n",
    "# # def perplexity_analysis_with_contributions(original_model, data_loader, criterion, num_iterations=5):\n",
    "# #     total_block_losses = [0.0 for _ in range(len(original_model.blocks))]\n",
    "\n",
    "# #     # Step 1: Compute the baseline loss (without block replacement)\n",
    "# #     print(\"Computing baseline loss without block replacement...\")\n",
    "# #     baseline_loss = compute_baseline_loss(original_model, data_loader, criterion)\n",
    "# #     print(f\"Baseline Loss: {baseline_loss}\")\n",
    "    \n",
    "# #     # Outer loop to run the analysis multiple times for averaging\n",
    "# #     for iteration in range(num_iterations):\n",
    "# #         print(f\"Iteration {iteration + 1}/{num_iterations}\")\n",
    "\n",
    "# #         # Iterate through each block for replacement\n",
    "# #         for block_idx in range(len(original_model.blocks)):\n",
    "# #             print(f\"Replacing block {block_idx}\")\n",
    "# #             # Replace one block at a time with a linear layer\n",
    "# #             modified_model = ModifiedMobileNetV3(original_model, block_to_replace=block_idx)\n",
    "# #             modified_model.to(general_device)\n",
    "\n",
    "# #             # Run validation and compute loss\n",
    "# #             modified_model.eval()\n",
    "# #             total_loss = 0.0\n",
    "# #             with torch.no_grad():\n",
    "# #                 for inputs, targets in data_loader:\n",
    "# #                     inputs, targets = inputs.to(general_device), targets.to(general_device)\n",
    "# #                     outputs = modified_model(inputs)\n",
    "# #                     loss = criterion(outputs, targets)\n",
    "# #                     total_loss += loss.item()\n",
    "\n",
    "# #             # Calculate average loss for the current block\n",
    "# #             average_loss = total_loss / len(data_loader)\n",
    "# #             print(f'Loss for block {block_idx} in iteration {iteration + 1}: {average_loss}')\n",
    "            \n",
    "# #             # Accumulate the loss for each block\n",
    "# #             total_block_losses[block_idx] += average_loss\n",
    "\n",
    "# #     # Step 2: Calculate the final averaged loss and contribution for each block across iterations\n",
    "# #     for block_idx in range(len(original_model.blocks)):\n",
    "# #         final_average_loss = total_block_losses[block_idx] / num_iterations\n",
    "# #         contribution_percentage = ((final_average_loss - baseline_loss) / baseline_loss) * 100\n",
    "# #         print(f'Final averaged loss after replacing block {block_idx}: {final_average_loss}')\n",
    "# #         print(f'Contribution to loss for block {block_idx}: {contribution_percentage:.2f}%')\n",
    "\n",
    "# # # Helper function to compute the baseline loss (without replacing any block)\n",
    "# # def compute_baseline_loss(original_model, data_loader, criterion):\n",
    "# #     original_model.to(general_device)\n",
    "# #     original_model.eval()\n",
    "# #     total_loss = 0.0\n",
    "# #     with torch.no_grad():\n",
    "# #         for inputs, targets in data_loader:\n",
    "# #             inputs, targets = inputs.to(general_device), targets.to(general_device)\n",
    "# #             outputs = original_model(inputs)\n",
    "# #             loss = criterion(outputs, targets)\n",
    "# #             total_loss += loss.item()\n",
    "    \n",
    "# #     baseline_loss = total_loss / len(data_loader)\n",
    "# #     return baseline_loss\n",
    "\n",
    "# # Function to perform perplexity analysis, return average loss, and calculate relative contribution percentages\n",
    "# def perplexity_analysis_with_contributions(original_model, data_loader, criterion, num_iterations=5):\n",
    "#     total_block_losses = [0.0 for _ in range(len(original_model.blocks))]\n",
    "\n",
    "#     # Step 1: Compute the baseline loss (without block replacement)\n",
    "#     print(\"Computing baseline loss without block replacement...\")\n",
    "#     baseline_loss = compute_baseline_loss(original_model, data_loader, criterion)\n",
    "#     print(f\"Baseline Loss: {baseline_loss}\")\n",
    "    \n",
    "#     # Outer loop to run the analysis multiple times for averaging\n",
    "#     for iteration in range(num_iterations):\n",
    "#         print(f\"Iteration {iteration + 1}/{num_iterations}\")\n",
    "\n",
    "#         # Iterate through each block for replacement\n",
    "#         for block_idx in range(len(original_model.blocks)):\n",
    "#             print(f\"Replacing block {block_idx}\")\n",
    "#             # Replace one block at a time with a linear layer\n",
    "#             modified_model = ModifiedMobileNetV3(original_model, block_to_replace=block_idx)\n",
    "#             # print(modified_model)\n",
    "#             modified_model.to(general_device)\n",
    "\n",
    "#             # Run validation and compute loss\n",
    "#             modified_model.eval()\n",
    "#             total_loss = 0.0\n",
    "#             with torch.no_grad():\n",
    "#                 for inputs, targets in data_loader:\n",
    "#                     inputs, targets = inputs.to(general_device), targets.to(general_device)\n",
    "#                     outputs = modified_model(inputs)\n",
    "#                     loss = criterion(outputs, targets)\n",
    "#                     total_loss += loss.item()\n",
    "\n",
    "#             # Calculate average loss for the current block\n",
    "#             average_loss = total_loss / len(data_loader)\n",
    "#             print(f'Loss for block {block_idx} in iteration {iteration + 1}: {average_loss}')\n",
    "            \n",
    "#             # Accumulate the loss for each block\n",
    "#             total_block_losses[block_idx] += average_loss\n",
    "\n",
    "#     # Step 2: Calculate the final averaged loss and contribution for each block across iterations\n",
    "#     total_increase_in_loss = 0.0\n",
    "#     block_increases = []\n",
    "    \n",
    "#     for block_idx in range(len(original_model.blocks)):\n",
    "#         final_average_loss = total_block_losses[block_idx] / num_iterations\n",
    "#         increase_in_loss = final_average_loss - baseline_loss\n",
    "#         block_increases.append(increase_in_loss)\n",
    "#         total_increase_in_loss += increase_in_loss  # Accumulate total increase in loss\n",
    "    \n",
    "#     # Step 3: Calculate the relative contribution of each block to the total increase in loss\n",
    "#     relative_contributions = []\n",
    "#     print(\"\\nRelative contribution of each block to total loss increase:\")\n",
    "#     for block_idx in range(len(original_model.blocks)):\n",
    "#         relative_contribution = (block_increases[block_idx] / total_increase_in_loss) * 100\n",
    "#         print(f'Block {block_idx} contributes {relative_contribution:.2f}% to the total increase in loss')\n",
    "#         relative_contributions.append(relative_contribution)\n",
    "\n",
    "#     return relative_contributions\n",
    "\n",
    "# # Helper function to compute the baseline loss (without replacing any block)\n",
    "# def compute_baseline_loss(original_model, data_loader, criterion):\n",
    "#     original_model.to(general_device)\n",
    "#     original_model.eval()\n",
    "#     total_loss = 0.0\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, targets in data_loader:\n",
    "#             inputs, targets = inputs.to(general_device), targets.to(general_device)\n",
    "#             outputs = original_model(inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             total_loss += loss.item()\n",
    "    \n",
    "#     baseline_loss = total_loss / len(data_loader)\n",
    "#     return baseline_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative_contribution = perplexity_analysis_with_contributions(original_model, test_loader, criterion = nn.MSELoss(), num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pruning_ratios(contributions, max_pruning_ratio=0.9, p=2):\n",
    "    \"\"\"\n",
    "    Calculate pruning ratios based on exponential scaling of the relative contributions.\n",
    "\n",
    "    Parameters:\n",
    "    - contributions (list): List of relative contributions (in percentages) of each block to total loss increase.\n",
    "    - max_pruning_ratio (float): Maximum pruning ratio to be assigned to the least important layer. Default is 0.9.\n",
    "    - p (int): Power for the nonlinear scaling. Default is 2 for quadratic scaling.\n",
    "\n",
    "    Returns:\n",
    "    - pruning_ratios (list): List of pruning ratios for each block.\n",
    "    \"\"\"\n",
    "    # Normalize the contributions to get values between 0 and 1\n",
    "    total_contribution = sum(contributions)\n",
    "    normalized_contributions = [contribution / total_contribution for contribution in contributions]\n",
    "\n",
    "    # Calculate the pruning factors using the nonlinear scaling (p is the power for nonlinearity)\n",
    "    pruning_factors = [(1 - nc)**p for nc in normalized_contributions]\n",
    "\n",
    "    # Scale by the maximum pruning ratio\n",
    "    pruning_ratios = [max_pruning_ratio * pf for pf in pruning_factors]\n",
    "\n",
    "    return pruning_ratios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 0 Pruning Ratio: 0.4100\n",
      "Block 1 Pruning Ratio: 0.5500\n",
      "Block 2 Pruning Ratio: 0.7400\n",
      "Block 3 Pruning Ratio: 0.8100\n",
      "Block 4 Pruning Ratio: 0.8800\n",
      "Block 5 Pruning Ratio: 0.9000\n"
     ]
    }
   ],
   "source": [
    "def calculate_pruning_ratios_intense(contributions, max_pruning_ratio=0.9, k=5):\n",
    "    \"\"\"\n",
    "    Calculate pruning ratios based on intense nonlinear scaling (exponential decay) of the relative contributions.\n",
    "\n",
    "    Parameters:\n",
    "    - contributions (list): List of relative contributions (in percentages) of each block to total loss increase.\n",
    "    - max_pruning_ratio (float): Maximum pruning ratio to be assigned to the least important layer. Default is 0.9.\n",
    "    - k (int): Factor controlling the intensity of the scaling (larger k makes the ratio more intense).\n",
    "\n",
    "    Returns:\n",
    "    - pruning_ratios (list): List of pruning ratios for each block.\n",
    "    \"\"\"\n",
    "    # Normalize the contributions to get values between 0 and 1\n",
    "    total_contribution = sum(contributions)\n",
    "    normalized_contributions = [contribution / total_contribution for contribution in contributions]\n",
    "\n",
    "    # Apply exponential decay to magnify the effect for less important blocks\n",
    "    pruning_factors = [np.exp(-k * nc) for nc in normalized_contributions]\n",
    "\n",
    "    # Normalize the pruning factors so they stay within the max pruning ratio\n",
    "    max_factor = max(pruning_factors)\n",
    "    normalized_factors = [pf / max_factor for pf in pruning_factors]\n",
    "\n",
    "    # Scale by the maximum pruning ratio\n",
    "    pruning_ratios = [max_pruning_ratio * nf for nf in normalized_factors]\n",
    "\n",
    "    pruning_ratios = [round(num, 2) for num in pruning_ratios]\n",
    "\n",
    "    return pruning_ratios\n",
    "\n",
    "# Example usage\n",
    "contributions = [27.12, 21.05, 15.29, 13.38, 11.85, 11.31]  # Contributions in percentage\n",
    "max_pruning_ratio = 0.9  # Maximum pruning ratio (90%)\n",
    "k = 5  # Controls the intensity of the scaling\n",
    "\n",
    "pruning_ratios = calculate_pruning_ratios_intense(contributions, max_pruning_ratio, k)\n",
    "\n",
    "# Print the pruning ratios for each block\n",
    "for i, ratio in enumerate(pruning_ratios):\n",
    "    print(f\"Block {i} Pruning Ratio: {ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_dominance_to_pruning_nonlinear(normalized_dominance_ratios, max_pruning_ratio=0.9, k=5):\n",
    "    \"\"\"\n",
    "    Nonlinearly map normalized dominance ratios to pruning ratios, where higher dominance ratios\n",
    "    result in more aggressive pruning (closer to max_pruning_ratio) and lower dominance ratios result in\n",
    "    less aggressive pruning.\n",
    "\n",
    "    Parameters:\n",
    "    - normalized_dominance_ratios (list): List of normalized dominance ratios for each block.\n",
    "    - max_pruning_ratio (float): Maximum pruning ratio to be assigned to the most dominant block. Default is 0.9.\n",
    "    - k (int): Factor controlling the intensity of the nonlinear scaling (larger k makes the scaling more intense).\n",
    "\n",
    "    Returns:\n",
    "    - pruning_ratios (list): List of pruning ratios for each block.\n",
    "    \"\"\"\n",
    "    # Normalize the dominance ratios to ensure they are between 0 and 1\n",
    "    max_dominance_ratio = max(normalized_dominance_ratios)\n",
    "    min_dominance_ratio = min(normalized_dominance_ratios)\n",
    "    \n",
    "    # Avoid division by zero in case all dominance ratios are the same\n",
    "    if max_dominance_ratio == min_dominance_ratio:\n",
    "        return [max_pruning_ratio] * len(normalized_dominance_ratios)\n",
    "\n",
    "    # Normalize dominance ratios between 0 and 1\n",
    "    normalized_ratios = [(ndr - min_dominance_ratio) / (max_dominance_ratio - min_dominance_ratio) \n",
    "                         for ndr in normalized_dominance_ratios]\n",
    "\n",
    "    # Apply nonlinear scaling using exponential function\n",
    "    pruning_factors = [np.exp(k * nr) for nr in normalized_ratios]\n",
    "\n",
    "    # Normalize the pruning factors to ensure the maximum value is scaled to max_pruning_ratio\n",
    "    max_factor = max(pruning_factors)\n",
    "    normalized_factors = [pf / max_factor for pf in pruning_factors]\n",
    "\n",
    "    # Scale by the maximum pruning ratio\n",
    "    pruning_ratios = [max_pruning_ratio * nf for nf in normalized_factors]\n",
    "\n",
    "    return pruning_ratios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 0 Pruning Ratio: 0.7200\n",
      "Block 1 Pruning Ratio: 0.7300\n",
      "Block 2 Pruning Ratio: 0.8200\n",
      "Block 3 Pruning Ratio: 0.9800\n",
      "Block 4 Pruning Ratio: 0.8700\n",
      "Block 5 Pruning Ratio: 0.8800\n"
     ]
    }
   ],
   "source": [
    "max_pruning_ratio = 0.98  # Maximum pruning ratio (90%)\n",
    "k = 1 # Controls the intensity of the scaling\n",
    "\n",
    "pruning_ratios = calculate_pruning_ratios_intense(relative_contribution, max_pruning_ratio, k)\n",
    "\n",
    "# Print the pruning ratios for each block\n",
    "for i, ratio in enumerate(pruning_ratios):\n",
    "    print(f\"Block {i} Pruning Ratio: {ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pruning_ratio = 0.97  # Maximum pruning ratio (90%)\n",
    "k = 5  # Controls the intensity of the scaling\n",
    "\n",
    "pruning_ratios = calculate_pruning_ratios_intense(overall_normalized_dominance_ratios, max_pruning_ratio, k)\n",
    "\n",
    "# Print the pruning ratios for each block\n",
    "for i, ratio in enumerate(pruning_ratios):\n",
    "    print(f\"Block {i} Pruning Ratio: {ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the contribution percentages for each block (from your analysis)\n",
    "# contributions = np.array(relative_contribution)\n",
    "\n",
    "# # Define total pruning target (for example, 50% overall pruning)\n",
    "# total_pruning_ratio = 0.95\n",
    "\n",
    "# # Step 1: Convert contributions to pruning ratios (inverse of contributions with a non-linear mapping)\n",
    "# # Apply a power function to make low contributions lead to more aggressive pruning (e.g., exponent = 2)\n",
    "# exponent = 2  # You can adjust the exponent to control the non-linearity\n",
    "# inverse_contributions = np.power(1 / contributions, exponent)\n",
    "\n",
    "# # Step 2: Normalize the pruning ratios so they sum to the total pruning ratio\n",
    "# normalized_pruning_ratios = np.minimum((inverse_contributions / np.sum(inverse_contributions) * total_pruning_ratio)*1, 0.95)\n",
    "\n",
    "# # Step 3: Print the pruning ratio for each block\n",
    "# for i, pruning_ratio in enumerate(normalized_pruning_ratios):\n",
    "#     print(f\"Pruning ratio for block {i}: {pruning_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =  copy.deepcopy(original_model)\n",
    "# device = general_device\n",
    "# model.to(device)\n",
    "\n",
    "# batch = next(iter(train_loader))\n",
    "# x, y = batch\n",
    "# x,y = x.to(device), y.to(device)\n",
    "# imp = tp.importance.TaylorImportance()\n",
    "\n",
    "# pruning_info = {\n",
    "#     i: {\"block\": model.blocks[i], \"pruning_ratio\": ratio}\n",
    "#     for i, ratio in enumerate(pruning_ratios)\n",
    "# }\n",
    "\n",
    "# if isinstance(imp, tp.importance.TaylorImportance):\n",
    "#     y_hat = model(x)\n",
    "#     loss = F.mse_loss(y_hat, y)\n",
    "#     loss.backward()\n",
    "\n",
    "# # First, collect the layers to be ignored (conv_stem, bn1, and classifier)\n",
    "# ignored_layers = [\n",
    "#     model.conv_stem, \n",
    "#     model.bn1,\n",
    "#     model.global_pool,\n",
    "#     model.conv_head,\n",
    "#     model.norm_head,\n",
    "#     model.act2,\n",
    "#     model.flatten,\n",
    "#     model.classifier\n",
    "# ]\n",
    "\n",
    "# # ignored_layers_group = []\n",
    "# # Iterate through the named modules of the model to add layers to be ignored\n",
    "# # for name, m in original_model.named_modules():\n",
    "# #     # Add layers from Sequential(3), Sequential(4), Sequential(5) and the classifier\n",
    "# #     if (isinstance(m, torch.nn.Linear) and m.out_features == 2):\n",
    "# #         ignored_layers_group.append(m)\n",
    "\n",
    "# # Example usage for pruning while ignoring other blocks\n",
    "# for i, info in pruning_info.items():\n",
    "#     block_to_prune = info[\"block\"]\n",
    "#     pruning_ratio = info[\"pruning_ratio\"]\n",
    "    \n",
    "#     # # Now add all other blocks to ignored layers except the current block to be pruned\n",
    "#     # for j, block in enumerate(model.blocks):\n",
    "#     #     if block != block_to_prune:\n",
    "#     #         ignored_layers_group.append(block)\n",
    "\n",
    "#     # Dynamically ignore other blocks except the current block to prune\n",
    "#     ignored_layers_block = [pruning_info[j][\"block\"] for j in range(len(pruning_info)) if j != i]\n",
    "\n",
    "#     # Combine ignored layers (including initial layers, classifier, and other blocks)\n",
    "#     combined_ignored_layers = []\n",
    "#     combined_ignored_layers = ignored_layers + ignored_layers_block\n",
    "#     # print(block_to_prune)\n",
    "    \n",
    "        \n",
    "#     print('Pruning ratio here is: ', pruning_ratio)\n",
    "    \n",
    "#     # Apply pruning\n",
    "#     pruner_group =  tp.pruner.MagnitudePruner( \n",
    "#         model,\n",
    "#         example_inputs=x,\n",
    "#         importance=imp,\n",
    "#         pruning_ratio=pruning_ratio,\n",
    "#         ignored_layers=combined_ignored_layers,\n",
    "#     )\n",
    "\n",
    "#     pruner_group.step()\n",
    "\n",
    "#     # if i < 2:\n",
    "#     #     print(model)\n",
    "\n",
    "#     example_inputs = torch.randn(1, 8, 4096).to(device)\n",
    "#     macs, nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "#     print(f\"MACs: {macs/1e9} G, #Params: {nparams/1e3} K\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(trained_model, prune_method, pruning_ratios, train_loader):\n",
    "    # Make a copy of the trained model\n",
    "    model = copy.deepcopy(trained_model)\n",
    "    device = general_device  # Assuming general_device is defined elsewhere\n",
    "    model.to(device)\n",
    "\n",
    "    pruning_info = {\n",
    "    i: {\"block\": model.blocks[i], \"pruning_ratio\": ratio}\n",
    "    for i, ratio in enumerate(pruning_ratios)\n",
    "}\n",
    "\n",
    "    if prune_method == 'channel_pruning_Taylor_importance':\n",
    "        imp = tp.importance.TaylorImportance() \n",
    "\n",
    "        # Prepare a batch from the train loader for pruning and backward pass\n",
    "        batch = next(iter(train_loader))\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Perform forward and backward passes to calculate importance scores if using TaylorImportance\n",
    "        if isinstance(imp, tp.importance.TaylorImportance):\n",
    "            y_hat = model(x)\n",
    "            loss = F.mse_loss(y_hat, y)\n",
    "            loss.backward()\n",
    "\n",
    "        # Define layers to always ignore (conv_stem, bn1, and classifier)\n",
    "        ignored_layers = [\n",
    "            # model.conv_stem, \n",
    "            # model.bn1,\n",
    "            model.global_pool,\n",
    "            model.conv_head,\n",
    "            model.norm_head,\n",
    "            model.act2,\n",
    "            model.flatten,\n",
    "            model.classifier\n",
    "        ]\n",
    "\n",
    "        # Assuming `pruning_info` is a dictionary with blocks and pruning ratios\n",
    "        # Example of how `pruning_info` can be structured:\n",
    "        # pruning_info = {i: {\"block\": model.blocks[i], \"pruning_ratio\": ratio} for i, ratio in enumerate(prune_ratios)}\n",
    "\n",
    "        # Prune each block while ignoring other layers\n",
    "        for i, info in pruning_info.items():\n",
    "            pruning_ratio = info[\"pruning_ratio\"]\n",
    "            \n",
    "            # Add all blocks to the ignored layers except the block being pruned\n",
    "            ignored_layers_block = [pruning_info[j][\"block\"] for j in range(len(pruning_info)) if j != i]\n",
    "\n",
    "            # Combine fixed ignored layers (conv_stem, bn1, classifier) with the ignored blocks\n",
    "            combined_ignored_layers = ignored_layers + ignored_layers_block\n",
    "\n",
    "            # Apply pruning using the combined ignored layers\n",
    "            pruner_group = tp.pruner.MagnitudePruner( \n",
    "                model,\n",
    "                example_inputs=x,\n",
    "                importance=imp,\n",
    "                pruning_ratio=pruning_ratio,\n",
    "                ignored_layers=combined_ignored_layers,\n",
    "                iterative_steps=1,\n",
    "            )\n",
    "\n",
    "            # Step through pruning\n",
    "            pruner_group.step()\n",
    "\n",
    "    # Counting MACs and Params after pruning\n",
    "    example_inputs = torch.randn(1, 8, 4096).to(device)  # Generate example input for calculating MACs and parameters\n",
    "    macs, nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "    print(f\"MACs: {macs / 1e9} G, #Params: {nparams / 1e3} K\")\n",
    "\n",
    "    # Free up GPU memory\n",
    "    del x, y, batch\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_pruning(trained_model, pruning_method, model_name_suffix, train_loader, val_loader, pruning_ratios, prune_amount):\n",
    "    checkpoint_filename = f\"pruning_results/model_pruned_{model_name_suffix}_amount_{prune_amount}.ckpt\"\n",
    "    final_model_path = f'pruning_results/model_final_pruned_{model_name_suffix}_amount_{prune_amount}.pth'\n",
    "\n",
    "   \n",
    "    if os.path.exists(checkpoint_filename) or os.path.exists(final_model_path):\n",
    "        print(f\"Model {model_name_suffix} at {prune_amount * 100}% pruning already exists. Skipping training.\")\n",
    "        return\n",
    "\n",
    "    pruned_model = prune_model(trained_model, pruning_method, pruning_ratios, train_loader)\n",
    "\n",
    "    rf_classifier = RFClassifier(pruned_model)\n",
    "\n",
    "    checkpoint_callback = L.callbacks.ModelCheckpoint(\n",
    "        dirpath='.',\n",
    "        filename=checkpoint_filename.replace(\".ckpt\", \"\"),\n",
    "        save_top_k=1,\n",
    "        verbose=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # Create the custom callback\n",
    "    custom_checkpoint = CustomCheckpoint()\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=50,\n",
    "        callbacks=[checkpoint_callback, custom_checkpoint],\n",
    "        accelerator='gpu',\n",
    "        devices=[3],\n",
    "        benchmark=True,\n",
    "        precision='32-true',\n",
    "    )\n",
    "\n",
    "    print(f\"Training the model with {pruning_method} applied at {prune_amount * 100}%...\")\n",
    "    trainer.fit(rf_classifier, train_loader, val_loader)\n",
    "\n",
    "    torch.save(rf_classifier.model, final_model_path)\n",
    "\n",
    "    print(f\"Model {pruning_method} at {prune_amount * 100}% pruning saved. \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.72, 0.73, 0.82, 0.98, 0.87, 0.88]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruning_ratios #= [0.7, 0.7, 0.8, 0.95, 0.84, 0.87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 0.002006328 G, #Params: 47.738 K\n",
      "Training the model with channel_pruning_Taylor_importance applied at 95.0%...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad.hallaq/workarea/venv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/mohammad.hallaq/workarea/MobileNet_compression exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/mohammad.hallaq/workarea/venv/lib/python3.10/site-packages/torch/_compile.py:24: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  return torch._dynamo.disable(fn, recursive)(*args, **kwargs)\n",
      "\n",
      "  | Name  | Type        | Params | Mode\n",
      "---------------------------------------------\n",
      "0 | model | MobileNetV3 | 47.7 K | eval\n",
      "---------------------------------------------\n",
      "47.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "47.7 K    Total params\n",
      "0.191     Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "258       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de89b761a8b747f49ba5a900173d4549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 790.7911\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62135b71a4954a9aa2caafd0974464ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfae33a17a4d4141956e8c78fa3a620a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 384: 'val_loss' reached 90.59425 (best 90.59425), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 90.5943\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f737fe79a9c4495684f95a892ab515e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 768: 'val_loss' reached 47.70231 (best 47.70231), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 47.7023\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742a90cbc8314b8e85fcd8e4808420ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 1152: 'val_loss' reached 40.60385 (best 40.60385), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 40.6038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f472ba5c0864a08a273a97410e42e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1536: 'val_loss' reached 37.68772 (best 37.68772), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 37.6877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64aab8daa234d5bb77c68f0cfa69d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1920: 'val_loss' reached 36.84002 (best 36.84002), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 36.8400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36df11647c7a4ea889e04b64cb177381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 2304: 'val_loss' reached 35.08345 (best 35.08345), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 35.0835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3966f4e2ade44bf1832f4cc7c8b19527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 2688: 'val_loss' reached 30.77495 (best 30.77495), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 30.7750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8728f21ec0014d6c85da7644b391ca18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 3072: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0808e42e21794ee4944bb0f3dbbd072c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 3456: 'val_loss' reached 28.32619 (best 28.32619), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 28.3262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc69954869c45fabba4e7e2a6cdfc78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 3840: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f6b9e8ad66477f9c5d0ed50f915590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 4224: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b33987d4264a05926eee54d6f7bdd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 4608: 'val_loss' reached 28.21970 (best 28.21970), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 28.2197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3d1203ec61405fb5ace2ce67707199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 4992: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6f552c43444f568cf13471455a69f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 5376: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe561dbb7bc4a4095599cd6414304e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 5760: 'val_loss' reached 27.02204 (best 27.02204), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 27.0220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14084ea44328418b88311dab66d31c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 6144: 'val_loss' reached 24.43827 (best 24.43827), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 24.4383\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cefb745d42f4785bd8942fc2c0479bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 6528: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940c0ad13e4d463490516e72bbc465f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 6912: 'val_loss' reached 24.33731 (best 24.33731), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 24.3373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8625b4176b334172957de1e32e1f7ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 7296: 'val_loss' reached 21.64221 (best 21.64221), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 21.6422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc504e9c17b44b10b86abbced7100a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 7680: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3f8be9d924493d8d341a25ba6c6f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 8064: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de69b27190444982b3401f4536b18960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 8448: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a84b2c43e8644c88fc90a434761daae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 8832: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893fe56815104bc691d254d2eea1b223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 9216: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcaa1cade1e34a55b2c1c15bf8604bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 9600: 'val_loss' reached 20.69756 (best 20.69756), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 20.6976\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1494d9cba5a4536843f0868471cedbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 9984: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb750fc8fcbe481c869ec056d6483318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 10368: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ab5ea305d740f7bdaca6ce8fce9fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 10752: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711b77a9425344d89d87252924ec5a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 11136: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15eec745897f4ba39dd3ebdbaed29e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 11520: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f5665b710c4b83b542b9fd1655d789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, global step 11904: 'val_loss' reached 20.59347 (best 20.59347), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 20.5935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff90c9397c884d6b87a9b653f5e8cdc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31, global step 12288: 'val_loss' reached 20.26570 (best 20.26570), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 20.2657\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0afc4f619e417fba7ce3838acdce8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32, global step 12672: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b9771e5b604317a50e154992b9c294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33, global step 13056: 'val_loss' reached 19.91413 (best 19.91413), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 19.9141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1697e2f9f1804f3294c022efce8a8b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34, global step 13440: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a675608763e461fb0a1aa0da1348ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35, global step 13824: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6836d6cce0b84c7293ef3b8a9edb9c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36, global step 14208: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5446e6d2a62f4fcf8b65f7af70a6e5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37, global step 14592: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7307b28b534a6da6dd46627dc73cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38, global step 14976: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a89a117a924280a7aebb905f6d89dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 15360: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65ba4e4f4224b7482549bbd613beae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40, global step 15744: 'val_loss' reached 19.09638 (best 19.09638), saving model to '/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/model_pruned_channel_pruning_Taylor_importance_amount_0.95.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with validation loss 19.0964\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db1e0e01aaf4d3eb395004c660725df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41, global step 16128: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a74e5d53061427f8bc39505aa6ef6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42, global step 16512: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0f7398e19d4cf68ebb02391e5f07a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43, global step 16896: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d413f89305a462897f4fe44ecf8e723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44, global step 17280: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883bb8377a05489cae611920fa69d5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45, global step 17664: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac932e4da7bd4d48809baf80ce7601f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46, global step 18048: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68ac0c889c64179b213048ee2ceb205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47, global step 18432: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510b0f33766d42eaacc2866168573221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48, global step 18816: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ce4a0df76f448bbbe43d55d6cb8a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 19200: 'val_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model channel_pruning_Taylor_importance at 95.0% pruning saved. \n"
     ]
    }
   ],
   "source": [
    "pruning_methods = ['channel_pruning_Taylor_importance']\n",
    "pruning_amounts = [0.95]  \n",
    "\n",
    "for method in pruning_methods:\n",
    "    for amount in pruning_amounts:\n",
    "        train_model_with_pruning(original_model, method, method, train_loader, test_loader, pruning_ratios, amount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = torch.load('/home/mohammad.hallaq/workarea/MobileNet_compression/pruning_results/best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quiver(all_targets, all_outputs, quiver_path: str):\n",
    "    \"\"\"\n",
    "    Creates and stores the quiver plot for given targets and predicted outputs\n",
    "    :args all_targets:\n",
    "    :args all_outputs:\n",
    "    \"\"\"\n",
    "    predictions_per_target = defaultdict(list)\n",
    "    errors_per_target = dict()\n",
    "\n",
    "    for idx, target_angles_tuple in enumerate(all_targets):\n",
    "        target_tuple = tuple(target_angles_tuple)\n",
    "        predictions_per_target[target_tuple].append(all_outputs[idx])\n",
    "    for target_tuple, list_of_predictions in predictions_per_target.items():\n",
    "        # predictions_per_target[target_tuple] = np.mean(list_of_predictions, axis=0)\n",
    "        errors_per_target[target_tuple] = np.subtract(target_tuple, np.mean(list_of_predictions, axis=0))\n",
    "\n",
    "    unique_targets = list(errors_per_target.keys())\n",
    "    unique_azimuth = [target[0] for target in unique_targets]\n",
    "    unique_elevation = [target[1] for target in unique_targets]\n",
    "    unique_erros = list(errors_per_target.values())\n",
    "    errors_azimuth = [target[0] for target in unique_erros]\n",
    "    errors_elevation = [target[1] for target in unique_erros]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(unique_azimuth, unique_elevation, color='red', label='True Angles')\n",
    "    plt.quiver(unique_azimuth, unique_elevation, errors_azimuth, errors_elevation,\n",
    "                angles='xy', scale_units='xy', scale=1, color='blue', label='Predicted Angles')\n",
    "    plt.xlim([-55, 55])\n",
    "    plt.ylim([-55, 55])\n",
    "    plt.xlabel('Azimuth')\n",
    "    plt.ylabel('Elevation')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.savefig(quiver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/360 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|| 360/360 [00:11<00:00, 30.41batch/s, Val Loss=0.703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Loss = 0.0019521186297003655\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "experiment_path = '/home/mohammad.hallaq/workarea/AoA-Pruning/experiments'\n",
    "device = general_device\n",
    "pruned_model = pruned_model.to(device)\n",
    "pruned_model.eval()\n",
    "eval_values = {'azimuth_true': [], 'azimuth_pred': [], 'elevation_true': [], 'elevation_pred': [], 'loss_value': []}\n",
    "\n",
    "test_loss, num_samples = 0, 0\n",
    "all_targets, all_outputs = np.zeros([1, 2]), np.zeros([1, 2])\n",
    "with torch.no_grad():\n",
    "    with tqdm(test_loader, desc='Testing', unit='batch') as pbar:\n",
    "        for sample_inputs, targets in pbar:\n",
    "            sample_inputs = sample_inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = pruned_model(sample_inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            eval_values['azimuth_pred'] = targets\n",
    "            num_samples += targets.shape[0]\n",
    "            test_loss += loss.item()/num_samples\n",
    "            all_targets = np.concatenate((all_targets, targets.cpu()))\n",
    "            all_outputs = np.concatenate((all_outputs, outputs.cpu()))\n",
    "            pbar.set_postfix({'Val Loss': test_loss})\n",
    "    all_outputs = all_outputs[1:]\n",
    "    all_targets = all_targets[1:]\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    print(f\"Test Set Loss = {test_loss}\")\n",
    "    quiver_path = os.path.join(experiment_path, \"testing_quiver_plot.png\")\n",
    "    plot_quiver(all_targets, all_outputs, quiver_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
